#!/usr/bin/env python3
"""
space-syntax-analyzer ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯ã€æ‹¡å¼µã•ã‚ŒãŸspace-syntax-analyzerã®å…¨æ©Ÿèƒ½ã‚’
ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã—ã¾ã™ã€‚
"""

import logging
import os
from pathlib import Path

# ãƒ­ã‚®ãƒ³ã‚°ã®è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)

logger = logging.getLogger(__name__)


def demo_basic_analysis():
    """åŸºæœ¬åˆ†æã®ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³"""
    print("="*50)
    print("ğŸš€ åŸºæœ¬åˆ†æãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³")
    print("="*50)
    
    try:
        from space_syntax_analyzer import SpaceSyntaxAnalyzer

        # ã‚¢ãƒŠãƒ©ã‚¤ã‚¶ãƒ¼ã®åˆæœŸåŒ–
        analyzer = SpaceSyntaxAnalyzer()
        
        # æ¸‹è°·é§…å‘¨è¾ºã®åˆ†æ
        print("\nğŸ“ åˆ†æå¯¾è±¡: æ¸‹è°·é§…å‘¨è¾º")
        results = analyzer.analyze_place("Shibuya Station, Tokyo, Japan")
        
        # çµæœã®è¡¨ç¤º
        report = analyzer.generate_report(results, "æ¸‹è°·é§…å‘¨è¾º")
        print(report)
        
        # å¯è¦–åŒ–
        print("\nğŸ“Š å¯è¦–åŒ–ã‚’è¡¨ç¤ºä¸­...")
        major_network, full_network = analyzer.get_network("Shibuya Station, Tokyo, Japan", "both")
        analyzer.visualize(major_network, full_network, results)
        
        # çµæœã®ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
        output_dir = Path("demo_output")
        output_dir.mkdir(exist_ok=True)
        
        analyzer.export_results(results, str(output_dir / "basic_analysis.csv"))
        print(f"âœ… åŸºæœ¬åˆ†æçµæœã‚’ {output_dir / 'basic_analysis.csv'} ã«ä¿å­˜")
        
    except Exception as e:
        logger.error(f"åŸºæœ¬åˆ†æãƒ‡ãƒ¢ã‚¨ãƒ©ãƒ¼: {e}")
        print(f"âŒ åŸºæœ¬åˆ†æã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")


def demo_enhanced_analysis():
    """æ‹¡å¼µåˆ†æï¼ˆè»¸ç·šåˆ†æãƒ»å¯è¦–é ˜åŸŸåˆ†æï¼‰ã®ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³"""
    print("\n" + "="*50)
    print("ğŸ”¬ æ‹¡å¼µåˆ†æãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³")
    print("="*50)
    
    try:
        from space_syntax_analyzer.core.enhanced_analyzer import (
            EnhancedSpaceSyntaxAnalyzer,
        )

        # æ‹¡å¼µã‚¢ãƒŠãƒ©ã‚¤ã‚¶ãƒ¼ã®åˆæœŸåŒ–
        analyzer = EnhancedSpaceSyntaxAnalyzer(
            enable_axial_analysis=True,
            enable_visibility_analysis=True,
            visibility_radius=100.0
        )
        
        print("\nğŸ“ åŒ…æ‹¬çš„åˆ†æå®Ÿè¡Œä¸­: äº¬éƒ½é§…å‘¨è¾º")
        print("   - åŸºæœ¬ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯åˆ†æ")
        print("   - è»¸ç·šåˆ†æï¼ˆAxial Analysisï¼‰")
        print("   - å¯è¦–é ˜åŸŸåˆ†æï¼ˆVisibility Analysisï¼‰")
        
        # åŒ…æ‹¬çš„åˆ†æã®å®Ÿè¡Œ
        results = analyzer.analyze_comprehensive("Kyoto Station, Kyoto, Japan")
        
        # çµ±åˆè©•ä¾¡ã®è¡¨ç¤º
        evaluation = results.get('integrated_evaluation', {})
        print(f"\nğŸ¯ çµ±åˆè©•ä¾¡çµæœ:")
        print(f"   ç·åˆã‚¹ã‚³ã‚¢: {evaluation.get('overall_score', 0):.1f}/100")
        print(f"   è©•ä¾¡ãƒ¬ãƒ™ãƒ«: {evaluation.get('evaluation_level', 'N/A')}")
        print(f"   å›éŠæ€§ã‚¹ã‚³ã‚¢: {evaluation.get('connectivity_score', 0):.1f}/100")
        print(f"   ã‚¢ã‚¯ã‚»ã‚¹æ€§ã‚¹ã‚³ã‚¢: {evaluation.get('accessibility_score', 0):.1f}/100")
        print(f"   åŠ¹ç‡æ€§ã‚¹ã‚³ã‚¢: {evaluation.get('efficiency_score', 0):.1f}/100")
        
        # è»¸ç·šåˆ†æçµæœã®è¡¨ç¤º
        axial_analysis = results.get('axial_analysis', {})
        if axial_analysis:
            network_metrics = axial_analysis.get('network_metrics', {})
            print(f"\nğŸ” è»¸ç·šåˆ†æçµæœ:")
            print(f"   è»¸ç·šæ•°: {network_metrics.get('axial_lines', 0)}")
            print(f"   æ ¼å­åº¦: {network_metrics.get('grid_axiality', 0):.3f}")
            print(f"   å¾ªç’°åº¦: {network_metrics.get('axial_ringiness', 0):.3f}")
        
        # å¯è¦–é ˜åŸŸåˆ†æçµæœã®è¡¨ç¤º
        visibility_analysis = results.get('visibility_analysis', {})
        if visibility_analysis:
            field_stats = visibility_analysis.get('visibility_field', {}).get('field_statistics', {})
            if field_stats:
                print(f"\nğŸ‘ï¸ å¯è¦–é ˜åŸŸåˆ†æçµæœ:")
                print(f"   ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ç‚¹æ•°: {field_stats.get('total_sampling_points', 0)}")
                print(f"   å¹³å‡å¯è¦–é¢ç©: {field_stats.get('mean_visible_area', 0):.1f}mÂ²")
                print(f"   å¯è¦–é ˜åŸŸå¤‰å‹•ä¿‚æ•°: {field_stats.get('std_visible_area', 0):.1f}")
        
        # åŒ…æ‹¬çš„å¯è¦–åŒ–
        print("\nğŸ“Š åŒ…æ‹¬çš„å¯è¦–åŒ–ã‚’è¡¨ç¤ºä¸­...")
        output_dir = Path("demo_output")
        analyzer.visualize_comprehensive(
            results, 
            save_path=str(output_dir / "comprehensive_analysis.png")
        )
        
        # å­¦è¡“ãƒ¬ãƒãƒ¼ãƒˆã®ç”Ÿæˆ
        print("\nğŸ“ å­¦è¡“ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆä¸­...")
        report_path = analyzer.generate_academic_report(
            results, 
            str(output_dir / "academic_report.txt"),
            include_visualizations=True
        )
        print(f"âœ… å­¦è¡“ãƒ¬ãƒãƒ¼ãƒˆã‚’ {report_path} ã«ä¿å­˜")
        
    except Exception as e:
        logger.error(f"æ‹¡å¼µåˆ†æãƒ‡ãƒ¢ã‚¨ãƒ©ãƒ¼: {e}")
        print(f"âŒ æ‹¡å¼µåˆ†æã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")


def demo_comparison_analysis():
    """è¤‡æ•°åœ°åŸŸæ¯”è¼ƒåˆ†æã®ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³"""
    print("\n" + "="*50)
    print("ğŸ™ï¸ è¤‡æ•°åœ°åŸŸæ¯”è¼ƒåˆ†æãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³")
    print("="*50)
    
    try:
        from space_syntax_analyzer.core.enhanced_analyzer import (
            EnhancedSpaceSyntaxAnalyzer,
        )
        
        analyzer = EnhancedSpaceSyntaxAnalyzer(
            enable_axial_analysis=True,
            enable_visibility_analysis=False  # é«˜é€ŸåŒ–ã®ãŸã‚ç„¡åŠ¹
        )
        
        # æ¯”è¼ƒå¯¾è±¡åœ°åŸŸ
        locations = [
            "Shibuya Station, Tokyo, Japan",
            "Kyoto Station, Kyoto, Japan", 
            "Osaka Station, Osaka, Japan"
        ]
        location_names = ["æ¸‹è°·", "äº¬éƒ½", "å¤§é˜ª"]
        
        print(f"\nğŸ“ æ¯”è¼ƒåˆ†æå¯¾è±¡: {', '.join(location_names)}")
        print("   å„åœ°åŸŸã®åŒ…æ‹¬çš„åˆ†æã‚’å®Ÿè¡Œä¸­...")
        
        # æ¯”è¼ƒåˆ†æã®å®Ÿè¡Œ
        comparison_results = analyzer.compare_locations(locations, location_names)
        
        # æ¯”è¼ƒçµæœã®è¡¨ç¤º
        comparison_analysis = comparison_results.get('comparison_analysis', {})
        rankings = comparison_analysis.get('rankings', {})
        
        if rankings:
            print(f"\nğŸ† å„æŒ‡æ¨™ã®ãƒ©ãƒ³ã‚­ãƒ³ã‚°:")
            
            for metric, ranking in rankings.items():
                print(f"\n   {metric}:")
                for i, (location, value) in enumerate(ranking[:3], 1):
                    print(f"     {i}ä½: {location} ({value:.2f})")
        
        # ç‰¹å¾´çš„åœ°åŸŸã®è¡¨ç¤º
        characteristic_locations = comparison_analysis.get('characteristic_locations', {})
        if characteristic_locations:
            print(f"\nğŸŒŸ ç‰¹å¾´çš„åœ°åŸŸ:")
            for characteristic, location in characteristic_locations.items():
                print(f"   {characteristic}: {location}")
        
        # æ¯”è¼ƒãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã®ä½œæˆ
        print("\nğŸ“Š æ¯”è¼ƒãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ä½œæˆä¸­...")
        output_dir = Path("demo_output")
        analyzer.create_comparison_dashboard(
            comparison_results,
            save_path=str(output_dir / "comparison_dashboard.png")
        )
        print(f"âœ… æ¯”è¼ƒãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã‚’ {output_dir / 'comparison_dashboard.png'} ã«ä¿å­˜")
        
    except Exception as e:
        logger.error(f"æ¯”è¼ƒåˆ†æãƒ‡ãƒ¢ã‚¨ãƒ©ãƒ¼: {e}")
        print(f"âŒ æ¯”è¼ƒåˆ†æã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")


def demo_axial_analysis_detailed():
    """è»¸ç·šåˆ†æã®è©³ç´°ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³"""
    print("\n" + "="*50)
    print("ğŸ” è»¸ç·šåˆ†æè©³ç´°ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³")
    print("="*50)
    
    try:
        from space_syntax_analyzer import SpaceSyntaxAnalyzer
        from space_syntax_analyzer.core.axial import AxialAnalyzer
        from space_syntax_analyzer.core.enhanced_visualization import EnhancedVisualizer

        # åŸºæœ¬ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®å–å¾—
        base_analyzer = SpaceSyntaxAnalyzer()
        major_network, _ = base_analyzer.get_network("Ginza, Tokyo, Japan", "major")
        
        print("\nğŸ“ è»¸ç·šåˆ†æå¯¾è±¡: éŠ€åº§åœ°åŒº")
        print(f"   åŸºæœ¬ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯: {major_network.number_of_nodes()}ãƒãƒ¼ãƒ‰, {major_network.number_of_edges()}ã‚¨ãƒƒã‚¸")
        
        # è»¸ç·šåˆ†æã®å®Ÿè¡Œ
        axial_analyzer = AxialAnalyzer()
        
        print("\nğŸ”§ è»¸ç·šãƒãƒƒãƒ—ä½œæˆä¸­...")
        axial_map = axial_analyzer.create_axial_map(major_network)
        print(f"   è»¸ç·šãƒãƒƒãƒ—: {axial_map.number_of_nodes()}è»¸ç·š")
        
        print("\nğŸ“Š Integration Valueè¨ˆç®—ä¸­...")
        global_integration = axial_analyzer.analyze_global_integration(axial_map)
        local_integration = axial_analyzer.analyze_local_integration(axial_map, radius=3)
        
        print(f"   Global Integration: {len(global_integration)}è»¸ç·š")
        print(f"   Local Integration (R3): {len(local_integration)}è»¸ç·š")
        
        # çµ±è¨ˆã®è¡¨ç¤º
        if global_integration:
            values = list(global_integration.values())
            print(f"\nğŸ“ˆ Integration Valueçµ±è¨ˆ:")
            print(f"   å¹³å‡: {sum(values)/len(values):.3f}")
            print(f"   æœ€å¤§: {max(values):.3f}")
            print(f"   æœ€å°: {min(values):.3f}")
        
        # å½¢æ…‹æŒ‡æ¨™ã®è¨ˆç®—
        network_metrics = axial_analyzer.calculate_axial_network_metrics(axial_map)
        print(f"\nğŸ—ï¸ è»¸ç·šãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å½¢æ…‹æŒ‡æ¨™:")
        print(f"   æ ¼å­åº¦(GA): {network_metrics.get('grid_axiality', 0):.3f}")
        print(f"   å¾ªç’°åº¦(AR): {network_metrics.get('axial_ringiness', 0):.3f}")
        print(f"   åˆ†ç¯€åº¦(AA): {network_metrics.get('axial_articulation', 0):.3f}")
        
        # å¯è¦–åŒ–
        print("\nğŸ“Š è»¸ç·šåˆ†æå¯è¦–åŒ–ä¸­...")
        visualizer = EnhancedVisualizer()
        output_dir = Path("demo_output")
        
        # Integration Valueåˆ†å¸ƒã®å¯è¦–åŒ–
        visualizer.plot_integration_value_distribution(
            global_integration,
            title="éŠ€åº§åœ°åŒº Integration Valueåˆ†å¸ƒ",
            save_path=str(output_dir / "integration_distribution.png")
        )
        
        # è»¸ç·šãƒãƒƒãƒ—ã®å¯è¦–åŒ–
        visualizer.plot_axial_map_with_integration(
            axial_map,
            global_integration,
            title="éŠ€åº§åœ°åŒº è»¸ç·šãƒãƒƒãƒ— (Global Integration)",
            save_path=str(output_dir / "axial_map.png")
        )
        
        print(f"âœ… è»¸ç·šåˆ†æå¯è¦–åŒ–çµæœã‚’ {output_dir} ã«ä¿å­˜")
        
    except Exception as e:
        logger.error(f"è»¸ç·šåˆ†æè©³ç´°ãƒ‡ãƒ¢ã‚¨ãƒ©ãƒ¼: {e}")
        print(f"âŒ è»¸ç·šåˆ†æè©³ç´°ãƒ‡ãƒ¢ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")


def demo_visibility_analysis_detailed():
    """å¯è¦–é ˜åŸŸåˆ†æã®è©³ç´°ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³"""
    print("\n" + "="*50)
    print("ğŸ‘ï¸ å¯è¦–é ˜åŸŸåˆ†æè©³ç´°ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³")
    print("="*50)
    
    try:
        from space_syntax_analyzer import SpaceSyntaxAnalyzer
        from space_syntax_analyzer.core.enhanced_visualization import EnhancedVisualizer
        from space_syntax_analyzer.core.visibility import VisibilityAnalyzer

        # åŸºæœ¬ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®å–å¾—
        base_analyzer = SpaceSyntaxAnalyzer()
        major_network, _ = base_analyzer.get_network("Harajuku, Tokyo, Japan", "major")
        
        print("\nğŸ“ å¯è¦–é ˜åŸŸåˆ†æå¯¾è±¡: åŸå®¿åœ°åŒº")
        print(f"   åŸºæœ¬ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯: {major_network.number_of_nodes()}ãƒãƒ¼ãƒ‰, {major_network.number_of_edges()}ã‚¨ãƒƒã‚¸")
        
        # å¯è¦–é ˜åŸŸåˆ†æã®å®Ÿè¡Œ
        visibility_analyzer = VisibilityAnalyzer(visibility_radius=75.0)
        
        print("\nğŸ” å¯è¦–é ˜åŸŸãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰åˆ†æä¸­...")
        visibility_field = visibility_analyzer.analyze_visibility_field(
            major_network, sampling_distance=30.0
        )
        
        field_stats = visibility_field.get('field_statistics', {})
        if field_stats:
            print(f"   ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ç‚¹æ•°: {field_stats.get('total_sampling_points', 0)}")
            print(f"   å¹³å‡å¯è¦–é¢ç©: {field_stats.get('mean_visible_area', 0):.1f}mÂ²")
            print(f"   å¯è¦–é¢ç©ç¯„å›²: {field_stats.get('min_visible_area', 0):.1f} - {field_stats.get('max_visible_area', 0):.1f}mÂ²")
        
        # å¤‰å‹•æ€§æŒ‡æ¨™ã®è¡¨ç¤º
        variability_metrics = visibility_field.get('variability_metrics', {})
        if variability_metrics:
            print(f"\nğŸ“Š å¯è¦–é ˜åŸŸå¤‰å‹•æ€§:")
            print(f"   é¢ç©å¤‰å‹•ä¿‚æ•°: {variability_metrics.get('area_coefficient_variation', 0):.3f}")
            print(f"   å¤šæ§˜æ€§æŒ‡æ¨™: {variability_metrics.get('spatial_diversity_index', 0):.3f}")
        
        print("\nğŸ”— è¦–è¦šçš„æ¥ç¶šæ€§åˆ†æä¸­...")
        visual_connectivity = visibility_analyzer.analyze_visual_connectivity(major_network)
        
        network_metrics = visual_connectivity.get('network_metrics', {})
        if network_metrics:
            print(f"   è¦–è¦šçš„ãƒãƒ¼ãƒ‰æ•°: {network_metrics.get('visual_nodes', 0)}")
            print(f"   è¦–è¦šçš„æ¥ç¶šæ•°: {network_metrics.get('visual_edges', 0)}")
            print(f"   å¹³å‡è¦–è¦šçš„æ¥ç¶šæ€§: {network_metrics.get('avg_visual_connectivity', 0):.3f}")
        
        # å˜ä¸€ç‚¹ã§ã®è©³ç´°Isoviståˆ†æ
        print("\nğŸ‘ï¸ ä»£è¡¨ç‚¹ã§ã®Isoviståˆ†æ...")
        sampling_points = visibility_field.get('sampling_points', [])
        if sampling_points:
            center_point = sampling_points[len(sampling_points)//2]  # ä¸­å¤®ä»˜è¿‘ã®ç‚¹
            isovist_result = visibility_analyzer.calculate_isovist(center_point, major_network)
            
            print(f"   è¦³æ¸¬ç‚¹: ({center_point[0]:.1f}, {center_point[1]:.1f})")
            print(f"   å¯è¦–é¢ç©: {isovist_result.get('visible_area', 0):.1f}mÂ²")
            print(f"   ã‚³ãƒ³ãƒ‘ã‚¯ãƒˆæ€§: {isovist_result.get('compactness', 0):.3f}")
            print(f"   é®è”½æ€§: {isovist_result.get('occlusivity', 0):.3f}")
        
        # å¯è¦–åŒ–
        print("\nğŸ“Š å¯è¦–é ˜åŸŸåˆ†æå¯è¦–åŒ–ä¸­...")
        visualizer = EnhancedVisualizer()
        output_dir = Path("demo_output")
        
        visualizer.plot_visibility_field(
            visibility_field,
            title="åŸå®¿åœ°åŒº å¯è¦–é ˜åŸŸãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰åˆ†æ",
            save_path=str(output_dir / "visibility_field.png")
        )
        
        # ãƒ‡ãƒ¼ã‚¿ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
        print("\nğŸ’¾ å¯è¦–é ˜åŸŸãƒ‡ãƒ¼ã‚¿ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆä¸­...")
        visibility_analyzer.export_visibility_results(
            visibility_field,
            str(output_dir / "visibility_data.csv"),
            format_type="csv"
        )
        
        print(f"âœ… å¯è¦–é ˜åŸŸåˆ†æçµæœã‚’ {output_dir} ã«ä¿å­˜")
        
    except Exception as e:
        logger.error(f"å¯è¦–é ˜åŸŸåˆ†æè©³ç´°ãƒ‡ãƒ¢ã‚¨ãƒ©ãƒ¼: {e}")
        print(f"âŒ å¯è¦–é ˜åŸŸåˆ†æè©³ç´°ãƒ‡ãƒ¢ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")


def demo_performance_test():
    """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆã®ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³"""
    print("\n" + "="*50)
    print("âš¡ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³")
    print("="*50)
    
    try:
        import time

        from space_syntax_analyzer.core.enhanced_analyzer import (
            EnhancedSpaceSyntaxAnalyzer,
        )

        # ç•°ãªã‚‹ã‚µã‚¤ã‚ºã®åœ°åŸŸã§ãƒ†ã‚¹ãƒˆ
        test_locations = [
            ("å°è¦æ¨¡", "Harajuku Station, Tokyo, Japan"),
            ("ä¸­è¦æ¨¡", "Shibuya, Tokyo, Japan"), 
            ("å¤§è¦æ¨¡", "Tokyo Station, Tokyo, Japan"),
        ]
        
        analyzer = EnhancedSpaceSyntaxAnalyzer(
            enable_axial_analysis=True,
            enable_visibility_analysis=True
        )
        
        performance_results = []
        
        for scale, location in test_locations:
            print(f"\nğŸ§ª {scale}åœ°åŸŸãƒ†ã‚¹ãƒˆ: {location}")
            
            start_time = time.time()
            
            try:
                # åŸºæœ¬ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å–å¾—æ™‚é–“
                network_start = time.time()
                major_network, full_network = analyzer.get_network(location, "both")
                network_time = time.time() - network_start
                
                network_size = major_network.number_of_nodes()
                print(f"   ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚µã‚¤ã‚º: {network_size}ãƒãƒ¼ãƒ‰")
                print(f"   ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å–å¾—æ™‚é–“: {network_time:.2f}ç§’")
                
                # åŸºæœ¬åˆ†ææ™‚é–“
                basic_start = time.time()
                area_ha = analyzer.network_manager.calculate_area_ha(major_network)
                basic_results = analyzer.analyze(major_network, full_network, area_ha)
                basic_time = time.time() - basic_start
                print(f"   åŸºæœ¬åˆ†ææ™‚é–“: {basic_time:.2f}ç§’")
                
                # è»¸ç·šåˆ†ææ™‚é–“ï¼ˆä¸­è¦æ¨¡ä»¥ä¸‹ã®ã¿ï¼‰
                axial_time = 0
                if network_size < 1000:  # å¤§è¦æ¨¡ã§ã¯è»¸ç·šåˆ†æã‚’ã‚¹ã‚­ãƒƒãƒ—
                    axial_start = time.time()
                    axial_results = analyzer._perform_axial_analysis(major_network)
                    axial_time = time.time() - axial_start
                    print(f"   è»¸ç·šåˆ†ææ™‚é–“: {axial_time:.2f}ç§’")
                else:
                    print(f"   è»¸ç·šåˆ†æ: ã‚¹ã‚­ãƒƒãƒ—ï¼ˆå¤§è¦æ¨¡ã®ãŸã‚ï¼‰")
                
                total_time = time.time() - start_time
                print(f"   ç·å‡¦ç†æ™‚é–“: {total_time:.2f}ç§’")
                
                performance_results.append({
                    'scale': scale,
                    'location': location,
                    'network_size': network_size,
                    'network_time': network_time,
                    'basic_time': basic_time,
                    'axial_time': axial_time,
                    'total_time': total_time,
                })
                
                print(f"   âœ… {scale}åœ°åŸŸãƒ†ã‚¹ãƒˆå®Œäº†")
                
            except Exception as e:
                print(f"   âŒ {scale}åœ°åŸŸãƒ†ã‚¹ãƒˆã§ã‚¨ãƒ©ãƒ¼: {e}")
                continue
        
        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµæœã®è¡¨ç¤º
        print(f"\nğŸ“Š ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆçµæœã‚µãƒãƒªãƒ¼:")
        print(f"{'è¦æ¨¡':<10} {'ãƒãƒ¼ãƒ‰æ•°':<10} {'å–å¾—æ™‚é–“':<10} {'åŸºæœ¬åˆ†æ':<10} {'è»¸ç·šåˆ†æ':<10} {'ç·æ™‚é–“':<10}")
        print("-" * 60)
        
        for result in performance_results:
            print(f"{result['scale']:<10} "
                  f"{result['network_size']:<10} "
                  f"{result['network_time']:<10.2f} "
                  f"{result['basic_time']:<10.2f} "
                  f"{result['axial_time']:<10.2f} "
                  f"{result['total_time']:<10.2f}")
        
        # æ¨å¥¨äº‹é …ã®è¡¨ç¤º
        print(f"\nğŸ’¡ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¨å¥¨äº‹é …:")
        print(f"   - 1000ãƒãƒ¼ãƒ‰æœªæº€: å…¨æ©Ÿèƒ½åˆ©ç”¨å¯èƒ½")
        print(f"   - 1000-3000ãƒãƒ¼ãƒ‰: è»¸ç·šåˆ†æã¯æ…é‡ã«å®Ÿè¡Œ")
        print(f"   - 3000ãƒãƒ¼ãƒ‰ä»¥ä¸Š: åŸºæœ¬åˆ†æã®ã¿æ¨å¥¨")
        
    except Exception as e:
        logger.error(f"ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
        print(f"âŒ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")


def main():
    """ãƒ¡ã‚¤ãƒ³ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³é–¢æ•°"""
    print("ğŸŒŸ space-syntax-analyzer æ‹¡å¼µæ©Ÿèƒ½ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³")
    print("="*70)
    
    # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ä½œæˆ
    output_dir = Path("demo_output")
    output_dir.mkdir(exist_ok=True)
    print(f"ğŸ“ å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {output_dir.absolute()}")
    
    # ãƒ‡ãƒ¢ãƒ¡ãƒ‹ãƒ¥ãƒ¼
    demos = [
        ("1", "åŸºæœ¬åˆ†æãƒ‡ãƒ¢", demo_basic_analysis),
        ("2", "æ‹¡å¼µåˆ†æãƒ‡ãƒ¢ï¼ˆè»¸ç·šãƒ»å¯è¦–é ˜åŸŸï¼‰", demo_enhanced_analysis),
        ("3", "è¤‡æ•°åœ°åŸŸæ¯”è¼ƒåˆ†æãƒ‡ãƒ¢", demo_comparison_analysis),
        ("4", "è»¸ç·šåˆ†æè©³ç´°ãƒ‡ãƒ¢", demo_axial_analysis_detailed),
        ("5", "å¯è¦–é ˜åŸŸåˆ†æè©³ç´°ãƒ‡ãƒ¢", demo_visibility_analysis_detailed),
        ("6", "ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¢", demo_performance_test),
        ("a", "å…¨ãƒ‡ãƒ¢å®Ÿè¡Œ", None),
    ]
    
    print(f"\nğŸ“‹ åˆ©ç”¨å¯èƒ½ãªãƒ‡ãƒ¢:")
    for code, name, _ in demos:
        print(f"   {code}: {name}")
    
    # è‡ªå‹•å®Ÿè¡Œãƒ¢ãƒ¼ãƒ‰ï¼ˆç’°å¢ƒå¤‰æ•°ã§åˆ¶å¾¡ï¼‰
    auto_mode = os.getenv('DEMO_AUTO_MODE', 'false').lower() == 'true'
    
    if auto_mode:
        print(f"\nğŸ¤– è‡ªå‹•å®Ÿè¡Œãƒ¢ãƒ¼ãƒ‰: åŸºæœ¬ãƒ‡ãƒ¢ã®ã¿å®Ÿè¡Œ")
        demo_basic_analysis()
    else:
        choice = input(f"\né¸æŠã—ã¦ãã ã•ã„ (1-6, a, q=çµ‚äº†): ").strip().lower()
        
        if choice == 'q':
            print("ğŸ‘‹ ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³çµ‚äº†")
            return
        elif choice == 'a':
            print(f"\nğŸš€ å…¨ãƒ‡ãƒ¢ã‚’é †æ¬¡å®Ÿè¡Œã—ã¾ã™...")
            for code, name, func in demos[:-1]:  # 'a'ä»¥å¤–ã®å…¨ã¦
                if func:
                    print(f"\nâ–¶ï¸ {name} é–‹å§‹")
                    func()
                    print(f"âœ… {name} å®Œäº†")
        else:
            # å€‹åˆ¥ãƒ‡ãƒ¢ã®å®Ÿè¡Œ
            for code, name, func in demos:
                if choice == code and func:
                    print(f"\nâ–¶ï¸ {name} é–‹å§‹")
                    func()
                    print(f"âœ… {name} å®Œäº†")
                    break
            else:
                print(f"âŒ ç„¡åŠ¹ãªé¸æŠ: {choice}")
    
    print(f"\nğŸ‰ ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Œäº†!")
    print(f"ğŸ“ çµæœãƒ•ã‚¡ã‚¤ãƒ«ã¯ {output_dir.absolute()} ã«ä¿å­˜ã•ã‚Œã¦ã„ã¾ã™")


if __name__ == "__main__":
    main()