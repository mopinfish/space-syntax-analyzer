# examples/station_analysis_demo.py
"""
é§…å‘¨è¾ºé“è·¯ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯åˆ†æãƒ‡ãƒ¢

è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰é§…æƒ…å ±ã‚’èª­ã¿è¾¼ã¿ã€å„é§…å‘¨è¾º800måœå†…ã®é“è·¯ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’åˆ†æ
"""

import json
import logging
import os
import sys
import time
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple, Union

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.insert(0, str(Path(__file__).parent.parent))

# æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè¨­å®š
try:
    import japanize_matplotlib
    JAPANESE_FONT_AVAILABLE = True
    print("âœ… æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè¨­å®šå®Œäº†")
except ImportError:
    import matplotlib.pyplot as plt
    plt.rcParams["font.family"] = ["DejaVu Sans"]
    JAPANESE_FONT_AVAILABLE = False
    print("âš ï¸ æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚è‹±èªãƒ•ã‚©ãƒ³ãƒˆã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")

import networkx as nx
import osmnx as ox
import pandas as pd

# ãƒ­ã‚®ãƒ³ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)

logger = logging.getLogger(__name__)

# åˆ†æçµæœä¿å­˜ç”¨
STATION_RESULTS = {}


class StationNetworkAnalyzer:
    """é§…å‘¨è¾ºãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯åˆ†æã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, config_path: str = "station_config.json"):
        """
        é§…å‘¨è¾ºãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯åˆ†æå™¨ã‚’åˆæœŸåŒ–
        
        Args:
            config_path: è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
        """
        self.config_path = Path(config_path)
        self.config = self._load_config()
        self.output_dir = Path(self.config.get("output_directory", "station_analysis_output"))
        self.output_dir.mkdir(exist_ok=True)
        
        # Space Syntax Analyzer ã®åˆæœŸåŒ–
        try:
            from space_syntax_analyzer.core.analyzer import SpaceSyntaxAnalyzer
            from space_syntax_analyzer.core.visualization import NetworkVisualizer
            
            self.analyzer = SpaceSyntaxAnalyzer()
            self.visualizer = NetworkVisualizer()
            print("âœ… Space Syntax Analyzer åˆæœŸåŒ–å®Œäº†")
        except ImportError as e:
            print(f"âŒ Space Syntax Analyzer ã®åˆæœŸåŒ–ã«å¤±æ•—: {e}")
            sys.exit(1)
    
    def _load_config(self) -> Dict[str, Any]:
        """è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿"""
        try:
            if not self.config_path.exists():
                print(f"âŒ è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {self.config_path}")
                print("ã‚µãƒ³ãƒ—ãƒ«è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆã—ã¾ã™ã‹ï¼Ÿ (y/n): ", end="")
                response = input().strip().lower()
                if response == 'y':
                    self._create_sample_config()
                    print(f"âœ… ã‚µãƒ³ãƒ—ãƒ«è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆã—ã¾ã—ãŸ: {self.config_path}")
                    print("è¨­å®šã‚’ç·¨é›†ã—ã¦ã‹ã‚‰å†å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
                sys.exit(1)
            
            with open(self.config_path, 'r', encoding='utf-8') as f:
                config = json.load(f)
            
            print(f"âœ… è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿å®Œäº†: {self.config_path}")
            return config
            
        except Exception as e:
            print(f"âŒ è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            sys.exit(1)
    
    def _create_sample_config(self):
        """ã‚µãƒ³ãƒ—ãƒ«è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆ"""
        sample_config = {
            "analysis_settings": {
                "radius_meters": 800,
                "network_type": "drive",
                "include_analysis": ["basic", "axial", "integration"],
                "save_graphml": True,
                "save_visualization": True,
                "background_map": True
            },
            "output_directory": "station_analysis_output",
            "stations": [
                {
                    "id": "shinjuku",
                    "name": "æ–°å®¿é§…",
                    "location": "Shinjuku Station, Tokyo, Japan",
                    "coordinates": null,
                    "graphml_path": null,
                    "description": "æ—¥æœ¬æœ€å¤§ã®ã‚¿ãƒ¼ãƒŸãƒŠãƒ«é§…"
                },
                {
                    "id": "shibuya", 
                    "name": "æ¸‹è°·é§…",
                    "location": "Shibuya Station, Tokyo, Japan",
                    "coordinates": [35.6580, 139.7016],
                    "graphml_path": null,
                    "description": "è‹¥è€…æ–‡åŒ–ã®ä¸­å¿ƒåœ°"
                },
                {
                    "id": "tokyo",
                    "name": "æ±äº¬é§…",
                    "location": "Tokyo Station, Tokyo, Japan",
                    "coordinates": null,
                    "graphml_path": "data/tokyo_station_network.graphml",
                    "description": "æ—¥æœ¬ã®é‰„é“ç¶²ã®ä¸­å¿ƒ"
                },
                {
                    "id": "matsumoto",
                    "name": "æ¾æœ¬é§…",
                    "location": "Matsumoto Station, Nagano, Japan",
                    "coordinates": [36.2408, 137.9677],
                    "graphml_path": null,
                    "description": "æ¾æœ¬åŸã®æœ€å¯„ã‚Šé§…"
                }
            ]
        }
        
        with open(self.config_path, 'w', encoding='utf-8') as f:
            json.dump(sample_config, f, ensure_ascii=False, indent=2)
    
    def analyze_all_stations(self) -> Dict[str, Any]:
        """å…¨é§…ã®åˆ†æã‚’å®Ÿè¡Œ"""
        print("ğŸš‰ é§…å‘¨è¾ºãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯åˆ†æã‚’é–‹å§‹ã—ã¾ã™")
        print("="*80)
        
        stations = self.config.get("stations", [])
        analysis_settings = self.config.get("analysis_settings", {})
        
        print(f"ğŸ“‹ åˆ†æå¯¾è±¡é§…æ•°: {len(stations)}")
        print(f"ğŸ“ åˆ†æåŠå¾„: {analysis_settings.get('radius_meters', 800)}m")
        print(f"ğŸ—ºï¸ ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ç¨®åˆ¥: {analysis_settings.get('network_type', 'drive')}")
        print()
        
        results = {}
        successful_analyses = []
        
        for i, station in enumerate(stations, 1):
            station_id = station.get("id", f"station_{i}")
            station_name = station.get("name", f"é§…{i}")
            
            print(f"ğŸ“ [{i}/{len(stations)}] {station_name} ({station_id}) åˆ†æä¸­...")
            
            try:
                result = self._analyze_single_station(station, analysis_settings)
                
                if result and not result.get('error', False):
                    results[station_id] = result
                    successful_analyses.append((station_id, station_name, result))
                    print(f"âœ… {station_name} åˆ†æå®Œäº†")
                    
                    # å¯è¦–åŒ–ã®ä¿å­˜
                    if analysis_settings.get('save_visualization', True):
                        self._save_station_visualizations(station, result)
                    
                else:
                    print(f"âŒ {station_name} åˆ†æå¤±æ•—: {result.get('error_message', 'ä¸æ˜')}")
                
            except Exception as e:
                print(f"âŒ {station_name} åˆ†æä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
                logger.error(f"é§…åˆ†æã‚¨ãƒ©ãƒ¼ ({station_id}): {e}")
            
            print()
        
        # çµæœã®ä¿å­˜
        global STATION_RESULTS
        STATION_RESULTS = results
        
        # æ¯”è¼ƒåˆ†æã®å®Ÿè¡Œ
        if len(successful_analyses) > 1:
            print("ğŸ“Š é§…é–“æ¯”è¼ƒåˆ†æã‚’å®Ÿè¡Œä¸­...")
            self._generate_comparative_analysis(successful_analyses)
        
        # çµ±åˆãƒ¬ãƒãƒ¼ãƒˆã®ç”Ÿæˆ
        self._generate_station_report(successful_analyses)
        
        print(f"ğŸ‰ åˆ†æå®Œäº†! çµæœã¯ {self.output_dir} ã«ä¿å­˜ã•ã‚Œã¾ã—ãŸ")
        return results
    
    def _analyze_single_station(self, station: Dict[str, Any], settings: Dict[str, Any]) -> Dict[str, Any]:
        """å˜ä¸€é§…ã®åˆ†æ"""
        station_id = station.get("id")
        station_name = station.get("name")
        
        # ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®å–å¾—ã¾ãŸã¯èª­ã¿è¾¼ã¿
        network = self._get_or_load_network(station, settings)
        
        if network is None:
            return {
                "error": True,
                "error_message": "ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®å–å¾—/èª­ã¿è¾¼ã¿ã«å¤±æ•—"
            }
        
        # åŸºæœ¬åˆ†æã®å®Ÿè¡Œ
        try:
            print(f"   ğŸ” åŸºæœ¬åˆ†æå®Ÿè¡Œä¸­...")
            
            # NetworkXã‚°ãƒ©ãƒ•ã‹ã‚‰åŸºæœ¬æŒ‡æ¨™ã‚’ç›´æ¥è¨ˆç®—
            basic_results = self._calculate_network_metrics(network)
            
            result = {
                "station_info": station,
                "network_data": {
                    "node_count": network.number_of_nodes(),
                    "edge_count": network.number_of_edges(),
                    "network_type": settings.get("network_type", "drive")
                },
                "basic_analysis": basic_results,
                "analysis_timestamp": datetime.now().isoformat(),
                "settings": settings
            }
            
            # æ‹¡å¼µåˆ†æï¼ˆåˆ©ç”¨å¯èƒ½ãªå ´åˆï¼‰
            include_analysis = settings.get("include_analysis", [])
            
            if "axial" in include_analysis:
                print(f"   ğŸ”„ è»¸ç·šåˆ†æå®Ÿè¡Œä¸­...")
                try:
                    axial_results = self._perform_axial_analysis(network)
                    result["axial_analysis"] = axial_results
                except Exception as e:
                    print(f"   âš ï¸ è»¸ç·šåˆ†æã‚¹ã‚­ãƒƒãƒ—: {e}")
                    result["axial_analysis"] = {"error": str(e)}
            
            if "integration" in include_analysis:
                print(f"   ğŸ“ˆ çµ±åˆè©•ä¾¡å®Ÿè¡Œä¸­...")
                try:
                    integration_results = self._calculate_integration_metrics(result)
                    result["integration_metrics"] = integration_results
                except Exception as e:
                    print(f"   âš ï¸ çµ±åˆè©•ä¾¡ã‚¹ã‚­ãƒƒãƒ—: {e}")
                    result["integration_metrics"] = {"error": str(e)}
            
            # GraphMLä¿å­˜
            if settings.get("save_graphml", True):
                graphml_path = self.output_dir / f"{station_id}_network.graphml"
                try:
                    ox.save_graphml(network, str(graphml_path))
                    result["saved_graphml"] = str(graphml_path)
                    print(f"   ğŸ’¾ GraphMLä¿å­˜: {graphml_path.name}")
                except Exception as e:
                    print(f"   âš ï¸ GraphMLä¿å­˜å¤±æ•—: {e}")
            
            return result
            
        except Exception as e:
            logger.error(f"é§…åˆ†æã‚¨ãƒ©ãƒ¼ ({station_id}): {e}")
            return {
                "error": True,
                "error_message": str(e)
            }
    
    def _calculate_network_metrics(self, network: nx.MultiDiGraph) -> Dict[str, Any]:
        """ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‹ã‚‰åŸºæœ¬æŒ‡æ¨™ã‚’è¨ˆç®—"""
        try:
            import numpy as np
            
            node_count = network.number_of_nodes()
            edge_count = network.number_of_edges()
            
            if node_count == 0:
                return {"error": "ç©ºã®ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯"}
            
            # åŸºæœ¬æŒ‡æ¨™ã®è¨ˆç®—
            degrees = dict(network.degree())
            avg_degree = sum(degrees.values()) / len(degrees) if degrees else 0
            max_degree = max(degrees.values()) if degrees else 0
            
            # å¯†åº¦è¨ˆç®—
            density = nx.density(network)
            
            # æ¥ç¶šæ€§ã®ç¢ºèª
            is_connected = nx.is_connected(network.to_undirected()) if node_count > 0 else False
            
            # æœ€å¤§é€£çµæˆåˆ†
            if not is_connected and node_count > 0:
                largest_cc = max(nx.connected_components(network.to_undirected()), key=len)
                largest_component_size = len(largest_cc)
            else:
                largest_component_size = node_count
            
            # é“è·¯ç·å»¶é•·ã®è¨ˆç®—ï¼ˆæ¦‚ç®—ï¼‰
            total_length = 0
            for u, v, data in network.edges(data=True):
                length = data.get('length', 0)
                if length > 0:
                    total_length += length
            
            # ã‚¨ãƒªã‚¢è¨ˆç®—ï¼ˆãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ã‹ã‚‰æ¦‚ç®—ï¼‰
            coords = []
            for node, data in network.nodes(data=True):
                if 'x' in data and 'y' in data:
                    coords.append([data['x'], data['y']])
            
            area_km2 = 0
            if coords:
                coords = np.array(coords)
                # ç°¡æ˜“é¢ç©è¨ˆç®—ï¼ˆçŸ©å½¢è¿‘ä¼¼ï¼‰
                x_range = coords[:, 0].max() - coords[:, 0].min()
                y_range = coords[:, 1].max() - coords[:, 1].min()
                # ç·¯åº¦çµŒåº¦ã‚’æ¦‚ç®—ã§ãƒ¡ãƒ¼ãƒˆãƒ«ã«å¤‰æ›ï¼ˆæ±äº¬ä»˜è¿‘ï¼‰
                x_meters = x_range * 111000 * np.cos(np.radians(35.6))
                y_meters = y_range * 111000
                area_km2 = (x_meters * y_meters) / 1000000  # km^2
            
            # Space Syntaxé¢¨ã®æŒ‡æ¨™è¨ˆç®—
            # Î±æŒ‡æ•°ï¼ˆå¾ªç’°æ€§ï¼‰: å®Ÿéš›ã®å›è·¯æ•° / æœ€å¤§å¯èƒ½å›è·¯æ•°
            alpha_index = max(0, edge_count - node_count + 1) if node_count > 2 else 0
            
            # Î²æŒ‡æ•°ï¼ˆè¤‡é›‘æ€§ï¼‰: ã‚¨ãƒƒã‚¸æ•° / ãƒãƒ¼ãƒ‰æ•°
            beta_index = edge_count / node_count if node_count > 0 else 0
            
            # Î³æŒ‡æ•°ï¼ˆæ¥ç¶šæ€§ï¼‰: å®Ÿéš›ã®ã‚¨ãƒƒã‚¸æ•° / æœ€å¤§å¯èƒ½ã‚¨ãƒƒã‚¸æ•°
            max_edges = node_count * (node_count - 1) / 2 if node_count > 1 else 1
            gamma_index = edge_count / max_edges if max_edges > 0 else 0
            
            # é“è·¯å¯†åº¦
            road_density = total_length / 1000 / area_km2 if area_km2 > 0 else 0  # km/km^2
            
            return {
                "analysis_status": "success",
                "node_count": node_count,
                "edge_count": edge_count,
                "avg_degree": avg_degree,
                "max_degree": max_degree,
                "density": density,
                "is_connected": is_connected,
                "largest_component_size": largest_component_size,
                "total_length_m": total_length,
                "area_km2": area_km2,
                "alpha_index": alpha_index,
                "beta_index": beta_index,
                "gamma_index": gamma_index,
                "road_density": road_density
            }
            
        except Exception as e:
            logger.error(f"ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æŒ‡æ¨™è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
            return {"error": str(e)}
    
    def _get_or_load_network(self, station: Dict[str, Any], settings: Dict[str, Any]) -> Optional[nx.MultiDiGraph]:
        """ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’å–å¾—ã¾ãŸã¯æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã¿"""
        graphml_path = station.get("graphml_path")
        
        # æ—¢å­˜ã®GraphMLãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚‹å ´åˆã¯èª­ã¿è¾¼ã¿
        if graphml_path and Path(graphml_path).exists():
            print(f"   ğŸ“‚ GraphMLãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿: {graphml_path}")
            try:
                return ox.load_graphml(graphml_path)
            except Exception as e:
                print(f"   âš ï¸ GraphMLèª­ã¿è¾¼ã¿å¤±æ•—: {e}, ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å–å¾—ã«åˆ‡ã‚Šæ›¿ãˆ")
        
        # ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’æ–°è¦å–å¾—
        radius = settings.get("radius_meters", 800)
        network_type = settings.get("network_type", "drive")
        
        coordinates = station.get("coordinates")
        location = station.get("location")
        
        try:
            if coordinates:
                # åº§æ¨™æŒ‡å®šã§ã®å–å¾—
                print(f"   ğŸŒ åº§æ¨™ã‹ã‚‰ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å–å¾— (åŠå¾„{radius}m)...")
                lat, lon = coordinates
                network = ox.graph_from_point((lat, lon), dist=radius, network_type=network_type)
            elif location:
                # åœ°åæŒ‡å®šã§ã®å–å¾—
                print(f"   ğŸ” åœ°åã‹ã‚‰ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å–å¾—: {location} (åŠå¾„{radius}m)...")
                network = ox.graph_from_address(location, dist=radius, network_type=network_type)
            else:
                print(f"   âŒ åº§æ¨™ã‚‚åœ°åã‚‚æŒ‡å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
                return None
            
            # ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®å‰å‡¦ç†
            network = ox.add_edge_speeds(network)
            network = ox.add_edge_travel_times(network)
            
            print(f"   âœ… ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å–å¾—å®Œäº†: {network.number_of_nodes()}ãƒãƒ¼ãƒ‰, {network.number_of_edges()}ã‚¨ãƒƒã‚¸")
            return network
            
        except Exception as e:
            print(f"   âŒ ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def _perform_axial_analysis(self, network: nx.MultiDiGraph) -> Dict[str, Any]:
        """è»¸ç·šåˆ†æã®å®Ÿè¡Œ"""
        try:
            from space_syntax_analyzer.core.axial import AxialAnalyzer
            
            axial_analyzer = AxialAnalyzer()
            axial_results = axial_analyzer.calculate_axial_summary(network)
            
            return axial_results
            
        except Exception as e:
            logger.warning(f"è»¸ç·šåˆ†æã‚¨ãƒ©ãƒ¼: {e}")
            return {"error": str(e)}
    
    def _calculate_integration_metrics(self, result: Dict[str, Any]) -> Dict[str, Any]:
        """çµ±åˆè©•ä¾¡æŒ‡æ¨™ã®è¨ˆç®—"""
        try:
            basic_analysis = result.get("basic_analysis", {})
            network_data = result.get("network_data", {})
            station_info = result.get("station_info", {})
            
            # åŸºæœ¬æŒ‡æ¨™
            node_count = network_data.get("node_count", 0)
            edge_count = network_data.get("edge_count", 0)
            
            # å¯†åº¦æŒ‡æ¨™
            if node_count > 1:
                density = edge_count / (node_count * (node_count - 1) / 2) if node_count > 1 else 0
            else:
                density = 0
            
            # ã‚¢ã‚¯ã‚»ã‚·ãƒ“ãƒªãƒ†ã‚£ã‚¹ã‚³ã‚¢ï¼ˆé§…å‘¨è¾ºç‰¹åŒ–ï¼‰
            accessibility_score = min(node_count / 100 * 50 + density * 50, 100)
            
            # æ¥ç¶šæ€§ã‚¹ã‚³ã‚¢
            avg_degree = (2 * edge_count / node_count) if node_count > 0 else 0
            connectivity_score = min(avg_degree * 10, 100)
            
            # é§…å‘¨è¾ºç·åˆã‚¹ã‚³ã‚¢
            station_score = (accessibility_score + connectivity_score) / 2
            
            # è©•ä¾¡ãƒ¬ãƒ™ãƒ«
            if station_score >= 80:
                evaluation_level = "A - éå¸¸ã«è‰¯å¥½"
            elif station_score >= 65:
                evaluation_level = "B - è‰¯å¥½"
            elif station_score >= 50:
                evaluation_level = "C - æ¨™æº–"
            elif station_score >= 35:
                evaluation_level = "D - æ”¹å–„ã®ä½™åœ°ã‚ã‚Š"
            else:
                evaluation_level = "E - å¤§å¹…æ”¹å–„å¿…è¦"
            
            return {
                "accessibility_score": accessibility_score,
                "connectivity_score": connectivity_score,
                "station_score": station_score,
                "evaluation_level": evaluation_level,
                "network_density": density,
                "average_degree": avg_degree,
                "analysis_radius": result.get("settings", {}).get("radius_meters", 800)
            }
            
        except Exception as e:
            logger.warning(f"çµ±åˆè©•ä¾¡è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
            return {"error": str(e)}
    
    def _save_station_visualizations(self, station: Dict[str, Any], result: Dict[str, Any]):
        """é§…ã®å¯è¦–åŒ–ã‚’ä¿å­˜"""
        try:
            station_id = station.get("id")
            station_name = station.get("name")
            
            # ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®å†å–å¾—ï¼ˆå¯è¦–åŒ–ç”¨ï¼‰
            settings = result.get("settings", {})
            network = self._get_or_load_network(station, settings)
            
            if network is None:
                print(f"   âš ï¸ å¯è¦–åŒ–ç”¨ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å–å¾—å¤±æ•—")
                return
            
            print(f"   ğŸ“Š å¯è¦–åŒ–ä¿å­˜ä¸­...")
            
            # èƒŒæ™¯åœ°å›³ã®åˆ©ç”¨å¯å¦
            background_map = (settings.get("background_map", True) and 
                            self.visualizer.contextily_available and 
                            self.visualizer.geopandas_available)
            
            # 1. åŸºæœ¬ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å›³
            network_path = self.output_dir / f"{station_id}_network.png"
            success = self.visualizer.save_network_graph(
                network,
                str(network_path),
                title=f"{station_name} å‘¨è¾ºé“è·¯ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯",
                show_basemap=background_map,
                basemap_alpha=0.6,
                edge_color="darkblue",
                node_color="red"
            )
            if success:
                print(f"   âœ… ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å›³: {network_path.name}")
            
            # 2. è»¸ç·šåˆ†æå›³ï¼ˆåˆ©ç”¨å¯èƒ½ãªå ´åˆï¼‰
            axial_analysis = result.get("axial_analysis", {})
            if axial_analysis and not axial_analysis.get("error"):
                axial_path = self.output_dir / f"{station_id}_axial.png"
                success = self.visualizer.save_axial_lines_only(
                    axial_analysis,
                    str(axial_path),
                    title=f"{station_name} è»¸ç·šåˆ†æ",
                    show_basemap=background_map,
                    basemap_alpha=0.6
                )
                if success:
                    print(f"   âœ… è»¸ç·šåˆ†æå›³: {axial_path.name}")
            
        except Exception as e:
            print(f"   âš ï¸ å¯è¦–åŒ–ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
            logger.warning(f"å¯è¦–åŒ–ä¿å­˜ã‚¨ãƒ©ãƒ¼ ({station.get('id')}): {e}")
    
    def _generate_comparative_analysis(self, successful_analyses: List[Tuple[str, str, Dict[str, Any]]]):
        """é§…é–“æ¯”è¼ƒåˆ†æã®ç”Ÿæˆ"""
        try:
            print("   ğŸ“Š æ¯”è¼ƒãƒãƒ£ãƒ¼ãƒˆç”Ÿæˆä¸­...")
            
            # æ¯”è¼ƒãƒ‡ãƒ¼ã‚¿ã®æº–å‚™
            comparison_data = []
            for station_id, station_name, result in successful_analyses:
                network_data = result.get("network_data", {})
                integration_metrics = result.get("integration_metrics", {})
                
                comparison_data.append({
                    "é§…ID": station_id,
                    "é§…å": station_name,
                    "ãƒãƒ¼ãƒ‰æ•°": network_data.get("node_count", 0),
                    "ã‚¨ãƒƒã‚¸æ•°": network_data.get("edge_count", 0),
                    "ã‚¢ã‚¯ã‚»ã‚·ãƒ“ãƒªãƒ†ã‚£ã‚¹ã‚³ã‚¢": integration_metrics.get("accessibility_score", 0),
                    "æ¥ç¶šæ€§ã‚¹ã‚³ã‚¢": integration_metrics.get("connectivity_score", 0),
                    "ç·åˆã‚¹ã‚³ã‚¢": integration_metrics.get("station_score", 0),
                    "è©•ä¾¡ãƒ¬ãƒ™ãƒ«": integration_metrics.get("evaluation_level", "ä¸æ˜")
                })
            
            # DataFrameã¨ã—ã¦ä¿å­˜
            df = pd.DataFrame(comparison_data)
            csv_path = self.output_dir / "station_comparison.csv"
            df.to_csv(csv_path, index=False, encoding='utf-8-sig')
            print(f"   âœ… æ¯”è¼ƒãƒ‡ãƒ¼ã‚¿: {csv_path.name}")
            
            # æ¯”è¼ƒãƒãƒ£ãƒ¼ãƒˆã®ç”Ÿæˆ
            self._create_comparison_charts(df)
            
        except Exception as e:
            print(f"   âš ï¸ æ¯”è¼ƒåˆ†æã‚¨ãƒ©ãƒ¼: {e}")
            logger.warning(f"æ¯”è¼ƒåˆ†æã‚¨ãƒ©ãƒ¼: {e}")
    
    def _create_comparison_charts(self, df: pd.DataFrame):
        """æ¯”è¼ƒãƒãƒ£ãƒ¼ãƒˆã®ä½œæˆ"""
        try:
            import matplotlib.pyplot as plt
            import numpy as np
            
            if df.empty:
                return
            
            fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))
            
            if JAPANESE_FONT_AVAILABLE:
                fig.suptitle("é§…å‘¨è¾ºãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ¯”è¼ƒåˆ†æ", fontsize=16, fontweight="bold")
            else:
                fig.suptitle("Station Network Comparison Analysis", fontsize=16, fontweight="bold")
            
            # 1. ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯è¦æ¨¡æ¯”è¼ƒ
            x_pos = np.arange(len(df))
            width = 0.35
            
            ax1.bar(x_pos - width/2, df["ãƒãƒ¼ãƒ‰æ•°"], width, label="ãƒãƒ¼ãƒ‰æ•°", color="#3498DB")
            ax1.bar(x_pos + width/2, df["ã‚¨ãƒƒã‚¸æ•°"], width, label="ã‚¨ãƒƒã‚¸æ•°", color="#E74C3C")
            ax1.set_title("ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯è¦æ¨¡æ¯”è¼ƒ" if JAPANESE_FONT_AVAILABLE else "Network Size Comparison")
            ax1.set_xlabel("é§…" if JAPANESE_FONT_AVAILABLE else "Station")
            ax1.set_ylabel("æ•°é‡" if JAPANESE_FONT_AVAILABLE else "Count")
            ax1.set_xticks(x_pos)
            ax1.set_xticklabels(df["é§…å"], rotation=45)
            ax1.legend()
            
            # 2. ã‚¹ã‚³ã‚¢æ¯”è¼ƒ
            ax2.bar(df["é§…å"], df["ç·åˆã‚¹ã‚³ã‚¢"], color="#2ECC71")
            ax2.set_title("ç·åˆã‚¹ã‚³ã‚¢æ¯”è¼ƒ" if JAPANESE_FONT_AVAILABLE else "Overall Score Comparison")
            ax2.set_xlabel("é§…" if JAPANESE_FONT_AVAILABLE else "Station")
            ax2.set_ylabel("ã‚¹ã‚³ã‚¢" if JAPANESE_FONT_AVAILABLE else "Score")
            ax2.set_ylim(0, 100)
            plt.setp(ax2.xaxis.get_majorticklabels(), rotation=45)
            
            # 3. ã‚¢ã‚¯ã‚»ã‚·ãƒ“ãƒªãƒ†ã‚£ vs æ¥ç¶šæ€§
            scatter = ax3.scatter(df["ã‚¢ã‚¯ã‚»ã‚·ãƒ“ãƒªãƒ†ã‚£ã‚¹ã‚³ã‚¢"], df["æ¥ç¶šæ€§ã‚¹ã‚³ã‚¢"], 
                                c=df["ç·åˆã‚¹ã‚³ã‚¢"], cmap="viridis", s=100, alpha=0.7)
            ax3.set_title("ã‚¢ã‚¯ã‚»ã‚·ãƒ“ãƒªãƒ†ã‚£ vs æ¥ç¶šæ€§" if JAPANESE_FONT_AVAILABLE else "Accessibility vs Connectivity")
            ax3.set_xlabel("ã‚¢ã‚¯ã‚»ã‚·ãƒ“ãƒªãƒ†ã‚£ã‚¹ã‚³ã‚¢" if JAPANESE_FONT_AVAILABLE else "Accessibility Score")
            ax3.set_ylabel("æ¥ç¶šæ€§ã‚¹ã‚³ã‚¢" if JAPANESE_FONT_AVAILABLE else "Connectivity Score")
            
            # é§…åã‚’ãƒã‚¤ãƒ³ãƒˆã«è¿½åŠ 
            for i, row in df.iterrows():
                ax3.annotate(row["é§…å"], (row["ã‚¢ã‚¯ã‚»ã‚·ãƒ“ãƒªãƒ†ã‚£ã‚¹ã‚³ã‚¢"], row["æ¥ç¶šæ€§ã‚¹ã‚³ã‚¢"]), 
                           xytext=(5, 5), textcoords='offset points', fontsize=9)
            
            plt.colorbar(scatter, ax=ax3, label="ç·åˆã‚¹ã‚³ã‚¢" if JAPANESE_FONT_AVAILABLE else "Overall Score")
            
            # 4. è©•ä¾¡ãƒ¬ãƒ™ãƒ«åˆ†å¸ƒ
            level_counts = df["è©•ä¾¡ãƒ¬ãƒ™ãƒ«"].value_counts()
            ax4.pie(level_counts.values, labels=level_counts.index, autopct='%1.1f%%', startangle=90)
            ax4.set_title("è©•ä¾¡ãƒ¬ãƒ™ãƒ«åˆ†å¸ƒ" if JAPANESE_FONT_AVAILABLE else "Evaluation Level Distribution")
            
            plt.tight_layout()
            
            chart_path = self.output_dir / "station_comparison_charts.png"
            plt.savefig(chart_path, dpi=300, bbox_inches="tight", facecolor='white')
            plt.close()
            
            print(f"   âœ… æ¯”è¼ƒãƒãƒ£ãƒ¼ãƒˆ: {chart_path.name}")
            
        except Exception as e:
            print(f"   âš ï¸ æ¯”è¼ƒãƒãƒ£ãƒ¼ãƒˆä½œæˆã‚¨ãƒ©ãƒ¼: {e}")
            logger.warning(f"æ¯”è¼ƒãƒãƒ£ãƒ¼ãƒˆä½œæˆã‚¨ãƒ©ãƒ¼: {e}")
    
    def _generate_station_report(self, successful_analyses: List[Tuple[str, str, Dict[str, Any]]]):
        """é§…åˆ†æçµ±åˆãƒ¬ãƒãƒ¼ãƒˆã®ç”Ÿæˆ"""
        try:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            report_path = self.output_dir / f"station_analysis_report_{timestamp}.md"
            
            with open(report_path, 'w', encoding='utf-8') as f:
                # ãƒ¬ãƒãƒ¼ãƒˆãƒ˜ãƒƒãƒ€ãƒ¼
                f.write("# é§…å‘¨è¾ºé“è·¯ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯åˆ†æãƒ¬ãƒãƒ¼ãƒˆ\n\n")
                f.write(f"**ç”Ÿæˆæ—¥æ™‚**: {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')}\n\n")
                
                # åˆ†ææ¦‚è¦
                f.write("## ğŸ“‹ åˆ†ææ¦‚è¦\n\n")
                f.write(f"- **åˆ†æå¯¾è±¡é§…æ•°**: {len(successful_analyses)}é§…\n")
                f.write(f"- **åˆ†æåŠå¾„**: {self.config.get('analysis_settings', {}).get('radius_meters', 800)}m\n")
                f.write(f"- **ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ç¨®åˆ¥**: {self.config.get('analysis_settings', {}).get('network_type', 'drive')}\n\n")
                
                # é§…åˆ¥è©³ç´°çµæœ
                f.write("## ğŸš‰ é§…åˆ¥åˆ†æçµæœ\n\n")
                
                for station_id, station_name, result in successful_analyses:
                    station_info = result.get("station_info", {})
                    network_data = result.get("network_data", {})
                    integration_metrics = result.get("integration_metrics", {})
                    
                    f.write(f"### {station_name}\n\n")
                    f.write(f"**é§…ID**: {station_id}\n\n")
                    f.write(f"**èª¬æ˜**: {station_info.get('description', 'èª¬æ˜ãªã—')}\n\n")
                    
                    # ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯åŸºæœ¬æƒ…å ±
                    f.write("#### ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯åŸºæœ¬æƒ…å ±\n\n")
                    f.write(f"- ãƒãƒ¼ãƒ‰æ•°: {network_data.get('node_count', 0):,}\n")
                    f.write(f"- ã‚¨ãƒƒã‚¸æ•°: {network_data.get('edge_count', 0):,}\n")
                    f.write(f"- ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å¯†åº¦: {integration_metrics.get('network_density', 0):.4f}\n")
                    f.write(f"- å¹³å‡æ¬¡æ•°: {integration_metrics.get('average_degree', 0):.2f}\n\n")
                    
                    # è©•ä¾¡æŒ‡æ¨™
                    if integration_metrics and not integration_metrics.get("error"):
                        f.write("#### è©•ä¾¡æŒ‡æ¨™\n\n")
                        f.write(f"- ã‚¢ã‚¯ã‚»ã‚·ãƒ“ãƒªãƒ†ã‚£ã‚¹ã‚³ã‚¢: {integration_metrics.get('accessibility_score', 0):.1f}/100\n")
                        f.write(f"- æ¥ç¶šæ€§ã‚¹ã‚³ã‚¢: {integration_metrics.get('connectivity_score', 0):.1f}/100\n")
                        f.write(f"- **ç·åˆã‚¹ã‚³ã‚¢**: {integration_metrics.get('station_score', 0):.1f}/100\n")
                        f.write(f"- **è©•ä¾¡ãƒ¬ãƒ™ãƒ«**: {integration_metrics.get('evaluation_level', 'ä¸æ˜')}\n\n")
                    
                    # è»¸ç·šåˆ†æçµæœ
                    axial_analysis = result.get("axial_analysis", {})
                    if axial_analysis and not axial_analysis.get("error"):
                        network_metrics = axial_analysis.get("network_metrics", {})
                        if network_metrics:
                            f.write("#### è»¸ç·šåˆ†æçµæœ\n\n")
                            f.write(f"- è»¸ç·šæ•°: {network_metrics.get('axial_lines', 0)}\n")
                            f.write(f"- è»¸ç·šæ¥ç¶šæ•°: {network_metrics.get('axial_connections', 0)}\n")
                            f.write(f"- æ ¼å­åº¦: {network_metrics.get('grid_axiality', 0):.3f}\n\n")
                
                # æ¯”è¼ƒåˆ†æ
                if len(successful_analyses) > 1:
                    f.write("## ğŸ“Š é§…é–“æ¯”è¼ƒåˆ†æ\n\n")
                    
                    # ãƒ©ãƒ³ã‚­ãƒ³ã‚°
                    sorted_stations = sorted(successful_analyses, 
                                           key=lambda x: x[2].get("integration_metrics", {}).get("station_score", 0), 
                                           reverse=True)
                    
                    f.write("### ç·åˆã‚¹ã‚³ã‚¢ãƒ©ãƒ³ã‚­ãƒ³ã‚°\n\n")
                    for i, (station_id, station_name, result) in enumerate(sorted_stations, 1):
                        score = result.get("integration_metrics", {}).get("station_score", 0)
                        level = result.get("integration_metrics", {}).get("evaluation_level", "ä¸æ˜")
                        f.write(f"{i}. **{station_name}**: {score:.1f}ç‚¹ ({level})\n")
                    
                    f.write("\n")
                    
                    # ç‰¹å¾´åˆ†æ
                    f.write("### ç‰¹å¾´åˆ†æ\n\n")
                    
                    # æœ€é«˜ã‚¹ã‚³ã‚¢é§…
                    best_station = sorted_stations[0]
                    f.write(f"**æœ€ã‚‚å„ªç§€ãªé§…**: {best_station[1]}\n")
                    f.write(f"- ç‰¹å¾´: é«˜ã„ã‚¢ã‚¯ã‚»ã‚·ãƒ“ãƒªãƒ†ã‚£ã¨æ¥ç¶šæ€§ã‚’å…¼ã­å‚™ãˆãŸé§…å‘¨è¾ºç’°å¢ƒ\n\n")
                    
                    # ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯è¦æ¨¡æœ€å¤§
                    largest_network = max(successful_analyses, 
                                        key=lambda x: x[2].get("network_data", {}).get("node_count", 0))
                    f.write(f"**æœ€å¤§ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯**: {largest_network[1]}\n")
                    f.write(f"- ãƒãƒ¼ãƒ‰æ•°: {largest_network[2].get('network_data', {}).get('node_count', 0):,}\n\n")
                
                # æ¨å¥¨äº‹é …
                f.write("## ğŸ’¡ æ¨å¥¨äº‹é …\n\n")
                f.write("### éƒ½å¸‚è¨ˆç”»ã¸ã®å¿œç”¨\n")
                f.write("- ç·åˆã‚¹ã‚³ã‚¢ã®é«˜ã„é§…ã¯ã€æ­©è¡Œè€…ãƒ»è‡ªè»¢è»Šåˆ©ç”¨ã®ä¿ƒé€²ã«é©ã—ã¦ã„ã‚‹\n")
                f.write("- æ¥ç¶šæ€§ã®ä½ã„é§…å‘¨è¾ºã§ã¯ã€æ–°ãŸãªé“è·¯æ•´å‚™ã‚’æ¤œè¨\n")
                f.write("- ã‚¢ã‚¯ã‚»ã‚·ãƒ“ãƒªãƒ†ã‚£ã®ä½ã„é§…ã§ã¯ã€æ—¢å­˜é“è·¯ã®æ”¹è‰¯ã‚’æ¤œè¨\n\n")
                
                f.write("### äº¤é€šæ”¿ç­–ã¸ã®ç¤ºå”†\n")
                f.write("- é«˜ã‚¹ã‚³ã‚¢é§…: å…¬å…±äº¤é€šã¨ã®çµç¯€æ©Ÿèƒ½å¼·åŒ–\n")
                f.write("- ä½ã‚¹ã‚³ã‚¢é§…: é§…å‰å†é–‹ç™ºã‚„é“è·¯ç¶²æ•´å‚™ã®å„ªå…ˆå®Ÿæ–½\n")
                f.write("- è»¸ç·šåˆ†æçµæœã‚’æ´»ç”¨ã—ãŸåŠ¹ç‡çš„ãªäº¤é€šæµè¨­è¨ˆ\n\n")
                
                # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
                f.write("---\n\n")
                f.write("## ğŸ“‹ åˆ†æãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿\n\n")
                f.write("- **åˆ†ææ‰‹æ³•**: Space Syntax Analysis + Network Analysis\n")
                f.write("- **ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹**: OpenStreetMap\n")
                f.write("- **åˆ†æãƒ„ãƒ¼ãƒ«**: OSMnx, NetworkX, Space Syntax Analyzer\n")
                f.write(f"- **è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«**: {self.config_path}\n")
                f.write(f"- **å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª**: {self.output_dir}\n")
            
            print(f"   âœ… çµ±åˆãƒ¬ãƒãƒ¼ãƒˆ: {report_path.name}")
            
        except Exception as e:
            print(f"   âš ï¸ ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            logger.warning(f"ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")


def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    print("ğŸš‰ é§…å‘¨è¾ºé“è·¯ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯åˆ†æãƒ‡ãƒ¢")
    print("="*80)
    
    # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ç¢ºèª
    config_files = ["station_config.json", "config/station_config.json", "examples/station_config.json"]
    config_path = None
    
    for path in config_files:
        if Path(path).exists():
            config_path = path
            break
    
    if not config_path:
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ‘ã‚¹ã§æ–°è¦ä½œæˆ
        config_path = "station_config.json"
    
    try:
        # åˆ†æå™¨ã®åˆæœŸåŒ–
        analyzer = StationNetworkAnalyzer(config_path)
        
        # åˆ†æå®Ÿè¡Œ
        results = analyzer.analyze_all_stations()
        
        print(f"\nğŸ“ çµæœã¯ {analyzer.output_dir} ã«ä¿å­˜ã•ã‚Œã¾ã—ãŸ")
        print("ğŸ’¡ ç”Ÿæˆã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«:")
        print("   - å„é§…ã®ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å›³ (PNG)")
        print("   - è»¸ç·šåˆ†æå›³ (PNG)")
        print("   - GraphMLãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ãƒ•ã‚¡ã‚¤ãƒ«")
        print("   - é§…é–“æ¯”è¼ƒãƒ‡ãƒ¼ã‚¿ (CSV)")
        print("   - æ¯”è¼ƒãƒãƒ£ãƒ¼ãƒˆ (PNG)")
        print("   - çµ±åˆåˆ†æãƒ¬ãƒãƒ¼ãƒˆ (Markdown)")
        
    except KeyboardInterrupt:
        print("\nğŸ‘‹ ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã‚ˆã£ã¦ä¸­æ–­ã•ã‚Œã¾ã—ãŸ")
    except Exception as e:
        logger.error(f"ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
        print(f"âŒ äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}")


if __name__ == "__main__":
    main()