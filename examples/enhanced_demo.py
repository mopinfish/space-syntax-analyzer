# æœ€å¼·ã®ãƒ•ã‚©ãƒ³ãƒˆè­¦å‘ŠæŠ‘åˆ¶
import logging
import warnings

# matplotlibé–¢é€£ã®å…¨è­¦å‘Šã‚’æŠ‘åˆ¶
warnings.filterwarnings('ignore', message='findfont: Font family.*not found')
warnings.filterwarnings('ignore', category=UserWarning, module='matplotlib')
warnings.filterwarnings('ignore', category=UserWarning, module='matplotlib.font_manager')
warnings.filterwarnings('ignore', message='Glyph.*missing from current font')
warnings.filterwarnings('ignore', message='.*font.*not found.*')

# matplotlibãƒ­ã‚¬ãƒ¼ã®è­¦å‘Šãƒ¬ãƒ™ãƒ«ã‚’ä¸Šã’ã‚‹
logging.getLogger('matplotlib').setLevel(logging.ERROR)
logging.getLogger('matplotlib.font_manager').setLevel(logging.ERROR)

# matplotlibè¨­å®šï¼ˆã‚¤ãƒ³ãƒãƒ¼ãƒˆå‰ï¼‰
import matplotlib

matplotlib.use('Agg')  # GUIãªã—ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰
import matplotlib.pyplot as plt

# æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè¨­å®š
try:
    import japanize_matplotlib

    # japanize_matplotlibãŒè‡ªå‹•çš„ã«æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆã‚’è¨­å®š
    print("âœ… æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè¨­å®šå®Œäº†")
    JAPANESE_FONT_AVAILABLE = True
except ImportError:
    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šè‹±èªãƒ•ã‚©ãƒ³ãƒˆ
    plt.rcParams["font.family"] = ["DejaVu Sans"]
    print("âš ï¸ æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚è‹±èªãƒ•ã‚©ãƒ³ãƒˆã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
    JAPANESE_FONT_AVAILABLE = False

plt.rcParams["axes.unicode_minus"] = False

# ãã®ä»–ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
import logging
import os
import sys
import time
from datetime import datetime
from pathlib import Path

import networkx as nx
import pandas as pd
from shapely.geometry.base import BaseGeometry

# ãƒ­ã‚®ãƒ³ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)

logger = logging.getLogger(__name__)

# ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°ï¼šåˆ†æçµæœä¿å­˜ç”¨
ANALYSIS_RESULTS = {}
CITY_NAMES_JP = {
    "Matsumoto, Nagano, Japan": "æ¾æœ¬å¸‚",
    "Nagano City, Nagano, Japan": "é•·é‡å¸‚",
    "Ueda, Nagano, Japan": "ä¸Šç”°å¸‚"
}


def demo_enhanced_comprehensive_analysis():
    """æœ€é©åŒ–ç‰ˆåŒ…æ‹¬çš„åˆ†æã®ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³"""
    print("="*60)
    print("ğŸš€ æœ€é©åŒ–ç‰ˆ Space Syntax åŒ…æ‹¬çš„åˆ†æãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³")
    print("="*60)
    
    try:
        # ã¾ãšåŸºæœ¬ã‚¢ãƒŠãƒ©ã‚¤ã‚¶ãƒ¼ã‚’ãƒ†ã‚¹ãƒˆ
        from space_syntax_analyzer.core.analyzer import SpaceSyntaxAnalyzer

        # æ‹¡å¼µã‚¢ãƒŠãƒ©ã‚¤ã‚¶ãƒ¼ã®åˆ©ç”¨å¯èƒ½æ€§ã‚’ãƒ†ã‚¹ãƒˆ
        enhanced_available = False
        try:
            # ã‚«ã‚¹ã‚¿ãƒ EnhancedSpaceSyntaxAnalyzerã‚¯ãƒ©ã‚¹ã‚’ä½œæˆ
            analyzer = create_optimized_enhanced_analyzer()
            enhanced_available = True
            print("âœ… æœ€é©åŒ–æ‹¡å¼µã‚¢ãƒŠãƒ©ã‚¤ã‚¶ãƒ¼åˆæœŸåŒ–æˆåŠŸ")
            analysis_type = "enhanced_optimized"
        except Exception as e:
            print(f"âš ï¸ æ‹¡å¼µã‚¢ãƒŠãƒ©ã‚¤ã‚¶ãƒ¼åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
            print("ğŸ”„ åŸºæœ¬ã‚¢ãƒŠãƒ©ã‚¤ã‚¶ãƒ¼ã‚’ä½¿ç”¨")
            analyzer = SpaceSyntaxAnalyzer()
            analysis_type = "basic"
        
        # é•·é‡çœŒã®ä»£è¡¨éƒ½å¸‚ã«å¤‰æ›´
        test_locations = [
            "Matsumoto, Nagano, Japan",      # æ¾æœ¬å¸‚
            "Nagano City, Nagano, Japan",    # é•·é‡å¸‚
            "Ueda, Nagano, Japan"           # ä¸Šç”°å¸‚
        ]
        
        successful_analyses = []
        
        for location in test_locations:
            location_jp = CITY_NAMES_JP.get(location, location)
            print(f"\nğŸ“ åˆ†æè©¦è¡Œ: {location_jp} ({location})")
            
            try:
                start_time = time.time()
                
                if enhanced_available:
                    # æœ€é©åŒ–æ‹¡å¼µåˆ†æã‚’å®Ÿè¡Œ
                    results = perform_optimized_enhanced_analysis(analyzer, location)
                else:
                    # åŸºæœ¬åˆ†æã‚’å®Ÿè¡Œ
                    results = analyzer.analyze_place(location)
                
                end_time = time.time()
                
                # ã‚¨ãƒ©ãƒ¼ãƒã‚§ãƒƒã‚¯ï¼ˆå‹å®‰å…¨æ€§ã‚’ç¢ºä¿ï¼‰
                if isinstance(results, dict) and results.get('error', False):
                    print(f"âŒ åˆ†æã‚¨ãƒ©ãƒ¼: {results.get('error_message', 'ä¸æ˜')}")
                    continue
                elif not isinstance(results, dict):
                    print(f"âŒ çµæœå‹ã‚¨ãƒ©ãƒ¼: äºˆæœŸã—ãªã„å‹ {type(results)}")
                    logger.error(f"çµæœå‹ã‚¨ãƒ©ãƒ¼: {type(results)} - {results}")
                    continue
                
                # æˆåŠŸ
                execution_time = end_time - start_time
                successful_analyses.append((location, results, analysis_type, execution_time))
                
                # ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°ã«ä¿å­˜ï¼ˆãƒ¬ãƒãƒ¼ãƒˆç”¨ï¼‰
                ANALYSIS_RESULTS[location] = {
                    'results': results,
                    'analysis_type': analysis_type,
                    'execution_time': execution_time,
                    'timestamp': datetime.now()
                }
                
                print(f"âœ… åˆ†ææˆåŠŸ! (å®Ÿè¡Œæ™‚é–“: {execution_time:.1f}ç§’)")
                
            except Exception as e:
                print(f"âŒ ä¾‹å¤–ç™ºç”Ÿ: {e}")
                logger.error(f"åˆ†æä¾‹å¤– ({location}): {e}")
                continue
        
        if successful_analyses:
            print(f"\nğŸ¯ åˆ†æå®Œäº†: {len(successful_analyses)}éƒ½å¸‚ã®åˆ†æã«æˆåŠŸ")
            
            # å„éƒ½å¸‚ã®çµæœè¡¨ç¤º
            for location, results, analysis_type, execution_time in successful_analyses:
                location_jp = CITY_NAMES_JP.get(location, location)
                print(f"\nğŸ“Š {location_jp}ã®åˆ†æçµæœ:")
                
                if "enhanced" in analysis_type:
                    display_enhanced_results(results)
                else:
                    display_basic_results(results)
                
                # çµæœã®ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
                export_results(analyzer, results, location, analysis_type)
                
                # å¯è¦–åŒ–ï¼ˆå¯èƒ½ãªå ´åˆï¼‰
                try_visualization(analyzer, results, location, analysis_type)
            
            # æ¯”è¼ƒåˆ†æãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
            generate_comparative_report(successful_analyses)
            
        else:
            print("âŒ ã™ã¹ã¦ã®åœ°åã§åˆ†æã«å¤±æ•—ã—ã¾ã—ãŸ")
            print("ğŸ’¡ è»¸ç·šåˆ†æå˜ä½“ãƒ‡ãƒ¢ã‚’å®Ÿè¡Œã—ã¾ã™")
            demo_axial_analysis_only()
            
    except ImportError as e:
        print(f"âŒ ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
        print("ğŸ’¡ åŸºæœ¬æ©Ÿèƒ½ã®ã¿ã§ãƒ‡ãƒ¢ã‚’å®Ÿè¡Œã—ã¾ã™")
        demo_basic_analysis_fallback()
    except Exception as e:
        print(f"âŒ äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}")
        logger.error(f"æ‹¡å¼µãƒ‡ãƒ¢å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")


def create_optimized_enhanced_analyzer():
    """æœ€é©åŒ–ã‚«ã‚¹ã‚¿ãƒ æ‹¡å¼µã‚¢ãƒŠãƒ©ã‚¤ã‚¶ãƒ¼ã‚’ä½œæˆ"""
    import networkx as nx  # NetworkXã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚’è¿½åŠ 
    import pandas as pd  # Pandasã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚’è¿½åŠ 

    from space_syntax_analyzer.core.analyzer import SpaceSyntaxAnalyzer
    from space_syntax_analyzer.core.axial import AxialAnalyzer
    from space_syntax_analyzer.core.visibility import VisibilityAnalyzer

    # åŸºæœ¬ã‚¢ãƒŠãƒ©ã‚¤ã‚¶ãƒ¼ã‚’æ‹¡å¼µ
    class OptimizedEnhancedAnalyzer(SpaceSyntaxAnalyzer):
        def __init__(self):
            # åŸºåº•ã‚¯ãƒ©ã‚¹ã®æ­£ã—ã„ã‚·ã‚°ãƒãƒãƒ£ã§åˆæœŸåŒ–
            super().__init__(network_type="drive", width_threshold=4.0)
            
            # æœ€é©åŒ–ã•ã‚ŒãŸæ‹¡å¼µæ©Ÿèƒ½ã‚’è¿½åŠ 
            self.enable_axial_analysis = True
            self.enable_visibility_analysis = True
            
            # æœ€é©åŒ–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
            self.max_intersections = 30  # äº¤å·®ç‚¹æ•°åˆ¶é™
            self.max_sampling_points = 50  # ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ç‚¹æ•°åˆ¶é™
            self.visibility_radius = 80.0  # å¯è¦–åŠå¾„çŸ­ç¸®
            
            # æ‹¡å¼µã‚¢ãƒŠãƒ©ã‚¤ã‚¶ãƒ¼ã®åˆæœŸåŒ–
            self.axial_analyzer = AxialAnalyzer()
            self.visibility_analyzer = VisibilityAnalyzer(
                visibility_radius=self.visibility_radius,
                max_intersections=self.max_intersections
            )
        
        def analyze_comprehensive(self, location, return_networks=False, analysis_level="global"):
            """æœ€é©åŒ–åŒ…æ‹¬çš„åˆ†æã®å®Ÿè¡Œ"""
            try:
                logger.info(f"æœ€é©åŒ–åŒ…æ‹¬çš„åˆ†æé–‹å§‹: {location}")
                
                # åŸºæœ¬åˆ†æã‚’å®Ÿè¡Œ
                basic_result = self.analyze_place(location, return_networks=True)
                
                # çµæœã®å‹ãƒã‚§ãƒƒã‚¯ã¨æ­£è¦åŒ–
                if isinstance(basic_result, tuple):
                    results, networks = basic_result
                    major_network, full_network = networks if networks else (None, None)
                else:
                    results = basic_result
                    major_network = full_network = None
                
                # ã‚¨ãƒ©ãƒ¼ãƒã‚§ãƒƒã‚¯
                if isinstance(results, dict) and results.get('error', False):
                    return results
                
                # åŒ…æ‹¬çš„åˆ†æçµæœã®æ§‹ç¯‰
                comprehensive_results = {
                    "basic_analysis": results,
                }
                
                # è»¸ç·šåˆ†æï¼ˆä¸¦åˆ—å®Ÿè¡Œå¯¾å¿œï¼‰
                if self.enable_axial_analysis and major_network:
                    logger.info("æœ€é©åŒ–è»¸ç·šåˆ†æé–‹å§‹")
                    try:
                        axial_results = self._perform_optimized_axial_analysis(
                            major_network, analysis_level
                        )
                        comprehensive_results["axial_analysis"] = axial_results
                        logger.info("è»¸ç·šåˆ†æå®Œäº†")
                    except Exception as e:
                        logger.warning(f"è»¸ç·šåˆ†æã‚¹ã‚­ãƒƒãƒ—: {e}")
                        comprehensive_results["axial_analysis"] = {"error": str(e)}
                
                # æœ€é©åŒ–å¯è¦–é ˜åŸŸåˆ†æ
                if self.enable_visibility_analysis and major_network:
                    logger.info("æœ€é©åŒ–å¯è¦–é ˜åŸŸåˆ†æé–‹å§‹")
                    try:
                        visibility_results = self._perform_optimized_visibility_analysis(major_network)
                        comprehensive_results["visibility_analysis"] = visibility_results
                        logger.info("å¯è¦–é ˜åŸŸåˆ†æå®Œäº†")
                    except Exception as e:
                        logger.warning(f"å¯è¦–é ˜åŸŸåˆ†æã‚¹ã‚­ãƒƒãƒ—: {e}")
                        comprehensive_results["visibility_analysis"] = {"error": str(e)}
                
                # çµ±åˆè©•ä¾¡ã®ç”Ÿæˆ
                try:
                    integrated_evaluation = self._generate_integrated_evaluation(comprehensive_results)
                    comprehensive_results["integrated_evaluation"] = integrated_evaluation
                except Exception as e:
                    logger.warning(f"çµ±åˆè©•ä¾¡ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
                    comprehensive_results["integrated_evaluation"] = {"error": str(e)}
                
                logger.info("æœ€é©åŒ–åŒ…æ‹¬çš„åˆ†æå®Œäº†")
                
                # æˆ»ã‚Šå€¤ã®å‹ã‚’çµ±ä¸€
                if return_networks:
                    return comprehensive_results, (major_network, full_network)
                else:
                    return comprehensive_results
                
            except Exception as e:
                logger.error(f"æœ€é©åŒ–åŒ…æ‹¬çš„åˆ†æã‚¨ãƒ©ãƒ¼: {e}")
                return {
                    "error": True,
                    "error_message": str(e),
                    "analysis_type": "optimized_comprehensive"
                }
        
        def _perform_optimized_axial_analysis(self, network, analysis_level="global"):
            """æœ€é©åŒ–è»¸ç·šåˆ†æã‚’å®Ÿè¡Œ"""
            try:
                import networkx as nx  # ãƒ­ãƒ¼ã‚«ãƒ«ã‚¤ãƒ³ãƒãƒ¼ãƒˆè¿½åŠ 

                # è»¸ç·šåˆ†æã®å®Ÿè¡Œ
                axial_results = self.axial_analyzer.calculate_axial_summary(network)
                
                # åˆ†æãƒ¬ãƒ™ãƒ«ã«å¿œã˜ãŸè¿½åŠ è¨ˆç®—ï¼ˆç°¡ç•¥åŒ–ï¼‰
                axial_map = axial_results.get("axial_map", nx.Graph())
                
                if analysis_level in ["global", "both"] and axial_map.number_of_nodes() > 0:
                    global_integration = self.axial_analyzer.analyze_global_integration(axial_map)
                    axial_results["global_integration"] = global_integration
                
                if analysis_level in ["local", "both"] and axial_map.number_of_nodes() > 0:
                    local_integration = self.axial_analyzer.analyze_local_integration(axial_map)
                    axial_results["local_integration"] = local_integration
                
                return axial_results
                
            except Exception as e:
                logger.warning(f"æœ€é©åŒ–è»¸ç·šåˆ†æå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
                return {"error": str(e)}
        
        def _perform_optimized_visibility_analysis(self, network):
            """æœ€é©åŒ–å¯è¦–é ˜åŸŸåˆ†æã‚’å®Ÿè¡Œ"""
            try:
                # æœ€é©åŒ–å¯è¦–é ˜åŸŸãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰åˆ†æ
                visibility_field = self.visibility_analyzer.analyze_visibility_field(
                    network, 
                    sampling_distance=40.0,  # ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°é–“éš”æ‹¡å¤§
                    max_points=self.max_sampling_points  # ç‚¹æ•°åˆ¶é™
                )
                
                # æœ€é©åŒ–è¦–è¦šçš„æ¥ç¶šæ€§åˆ†æ
                visual_connectivity = self.visibility_analyzer.analyze_visual_connectivity(network)
                
                return {
                    "visibility_field": visibility_field,
                    "visual_connectivity": visual_connectivity,
                }
                
            except Exception as e:
                logger.warning(f"æœ€é©åŒ–å¯è¦–é ˜åŸŸåˆ†æå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
                return {"error": str(e)}
        
        def _generate_integrated_evaluation(self, results):
            """çµ±åˆè©•ä¾¡ã‚’ç”Ÿæˆ"""
            try:
                import pandas as pd  # ãƒ­ãƒ¼ã‚«ãƒ«ã‚¤ãƒ³ãƒãƒ¼ãƒˆè¿½åŠ 
                
                basic_analysis = results.get("basic_analysis", {})
                
                # ä¸»è¦é“è·¯ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®æŒ‡æ¨™ã‚’å–å¾—
                major_network = basic_analysis.get("major_network")
                if not major_network:
                    return {"error": "ä¸»è¦é“è·¯ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“"}
                
                # å›éŠæ€§ã‚¹ã‚³ã‚¢
                alpha = major_network.get("alpha_index", 0)
                gamma = major_network.get("gamma_index", 0)
                connectivity_score = min((alpha + gamma) / 2, 100)
                
                # ã‚¢ã‚¯ã‚»ã‚¹æ€§ã‚¹ã‚³ã‚¢
                road_density = major_network.get("road_density", 0)
                accessibility_score = min(road_density * 5, 100)
                
                # åŠ¹ç‡æ€§ã‚¹ã‚³ã‚¢
                circuity = major_network.get("avg_circuity", 1.0)
                efficiency_score = max(0, min((2.0 - circuity) / 1.0 * 100, 100))
                
                # ç·åˆã‚¹ã‚³ã‚¢
                overall_score = (connectivity_score + accessibility_score + efficiency_score) / 3
                
                # è©•ä¾¡ãƒ¬ãƒ™ãƒ«ã®åˆ¤å®š
                if overall_score >= 80:
                    evaluation_level = "A - å„ªç§€"
                elif overall_score >= 65:
                    evaluation_level = "B - è‰¯å¥½"
                elif overall_score >= 50:
                    evaluation_level = "C - æ¨™æº–"
                elif overall_score >= 35:
                    evaluation_level = "D - è¦æ”¹å–„"
                else:
                    evaluation_level = "E - å¤§å¹…æ”¹å–„å¿…è¦"
                
                return {
                    "connectivity_score": connectivity_score,
                    "accessibility_score": accessibility_score,
                    "efficiency_score": efficiency_score,
                    "overall_score": overall_score,
                    "evaluation_level": evaluation_level,
                    "analysis_timestamp": pd.Timestamp.now().isoformat(),
                }
                
            except Exception as e:
                logger.warning(f"çµ±åˆè©•ä¾¡ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
                return {"error": str(e)}
    
    return OptimizedEnhancedAnalyzer()


def perform_optimized_enhanced_analysis(analyzer, location):
    """æœ€é©åŒ–æ‹¡å¼µåˆ†æã‚’å®Ÿè¡Œ"""
    try:
        result = analyzer.analyze_comprehensive(
            location, 
            return_networks=True, 
            analysis_level="global"  # globalã®ã¿ã§é«˜é€ŸåŒ–
        )
        
        # ã‚¿ãƒ—ãƒ«ãŒè¿”ã•ã‚ŒãŸå ´åˆã®å‡¦ç†
        if isinstance(result, tuple):
            comprehensive_results, networks = result
            return comprehensive_results
        else:
            # è¾æ›¸ãŒç›´æ¥è¿”ã•ã‚ŒãŸå ´åˆ
            return result
            
    except Exception as e:
        logger.error(f"æœ€é©åŒ–æ‹¡å¼µåˆ†æã‚¨ãƒ©ãƒ¼: {e}")
        return {
            "error": True,
            "error_message": str(e)
        }


def display_enhanced_results(results):
    """æœ€é©åŒ–æ‹¡å¼µåˆ†æçµæœã®è¡¨ç¤º"""
    print(f"\nğŸ“Š æœ€é©åŒ–æ‹¡å¼µåˆ†æçµæœ:")
    
    # åŸºæœ¬åˆ†æçµæœ
    basic_analysis = results.get('basic_analysis', {})
    if basic_analysis:
        major_network = basic_analysis.get('major_network', {})
        if major_network:
            print(f"   åŸºæœ¬ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æŒ‡æ¨™:")
            print(f"     ãƒãƒ¼ãƒ‰æ•°: {major_network.get('node_count', 0):,}")
            print(f"     ã‚¨ãƒƒã‚¸æ•°: {major_network.get('edge_count', 0):,}")
            print(f"     Î±æŒ‡æ•°: {major_network.get('alpha_index', 0):.2f}")
            print(f"     Î³æŒ‡æ•°: {major_network.get('gamma_index', 0):.2f}")
            print(f"     é“è·¯å¯†åº¦: {major_network.get('road_density', 0):.2f} km/kmÂ²")
            print(f"     å¹³å‡è¿‚å›ç‡: {major_network.get('avg_circuity', 0):.2f}")
    
    # è»¸ç·šåˆ†æçµæœ
    axial_analysis = results.get('axial_analysis', {})
    if axial_analysis and not axial_analysis.get('error'):
        network_metrics = axial_analysis.get('network_metrics', {})
        integration_stats = axial_analysis.get('integration_statistics', {})
        
        print(f"   è»¸ç·šåˆ†æ:")
        if network_metrics:
            print(f"     è»¸ç·šæ•°: {network_metrics.get('axial_lines', 0)}")
            print(f"     è»¸ç·šæ¥ç¶šæ•°: {network_metrics.get('axial_connections', 0)}")
            print(f"     æ ¼å­åº¦: {network_metrics.get('grid_axiality', 0):.3f}")
        
        if integration_stats:
            print(f"     çµ±åˆå€¤å¹³å‡: {integration_stats.get('mean', 0):.3f}")
    
    # å¯è¦–é ˜åŸŸåˆ†æçµæœ
    visibility_analysis = results.get('visibility_analysis', {})
    if visibility_analysis and not visibility_analysis.get('error'):
        visibility_field = visibility_analysis.get('visibility_field', {})
        field_stats = visibility_field.get('field_statistics', {})
        visual_connectivity = visibility_analysis.get('visual_connectivity', {})
        
        print(f"   å¯è¦–é ˜åŸŸåˆ†æ:")
        if field_stats:
            print(f"     å¹³å‡å¯è¦–é¢ç©: {field_stats.get('mean_visible_area', 0):.1f} mÂ²")
            print(f"     ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ç‚¹æ•°: {field_stats.get('total_sampling_points', 0)}")
        
        if visual_connectivity:
            network_metrics = visual_connectivity.get('network_metrics', {})
            if network_metrics:
                print(f"     è¦–è¦šçš„æ¥ç¶šãƒãƒ¼ãƒ‰æ•°: {network_metrics.get('visual_nodes', 0)}")
                print(f"     è¦–è¦šçš„æ¥ç¶šã‚¨ãƒƒã‚¸æ•°: {network_metrics.get('visual_edges', 0)}")
    
    # çµ±åˆè©•ä¾¡
    integrated_evaluation = results.get('integrated_evaluation', {})
    if integrated_evaluation and not integrated_evaluation.get('error'):
        print(f"   çµ±åˆè©•ä¾¡:")
        print(f"     å›éŠæ€§ã‚¹ã‚³ã‚¢: {integrated_evaluation.get('connectivity_score', 0):.1f}/100")
        print(f"     ã‚¢ã‚¯ã‚»ã‚¹æ€§ã‚¹ã‚³ã‚¢: {integrated_evaluation.get('accessibility_score', 0):.1f}/100")
        print(f"     åŠ¹ç‡æ€§ã‚¹ã‚³ã‚¢: {integrated_evaluation.get('efficiency_score', 0):.1f}/100")
        print(f"     ç·åˆã‚¹ã‚³ã‚¢: {integrated_evaluation.get('overall_score', 0):.1f}/100")
        print(f"     è©•ä¾¡ãƒ¬ãƒ™ãƒ«: {integrated_evaluation.get('evaluation_level', 'è©•ä¾¡ä¸å¯')}")


def display_basic_results(results):
    """åŸºæœ¬åˆ†æçµæœã®è¡¨ç¤º"""
    print(f"\nğŸ“Š åŸºæœ¬åˆ†æçµæœ:")
    
    major_network = results.get('major_network', {})
    if major_network:
        print(f"   ä¸»è¦é“è·¯ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯:")
        print(f"     ãƒãƒ¼ãƒ‰æ•°: {major_network.get('node_count', 0):,}")
        print(f"     ã‚¨ãƒƒã‚¸æ•°: {major_network.get('edge_count', 0):,}")
        print(f"     Î±æŒ‡æ•°: {major_network.get('alpha_index', 0):.2f}")
        print(f"     Î³æŒ‡æ•°: {major_network.get('gamma_index', 0):.2f}")
        print(f"     é“è·¯å¯†åº¦: {major_network.get('road_density', 0):.2f} km/kmÂ²")


def export_results(analyzer, results, location, analysis_type):
    """çµæœã®ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆï¼ˆã‚¿ãƒ—ãƒ«ã‚­ãƒ¼å¯¾å¿œç‰ˆï¼‰"""
    try:
        output_dir = Path("demo_output")
        output_dir.mkdir(exist_ok=True)
        
        timestamp = time.strftime("%Y%m%d_%H%M%S")
        filename = f"{location.replace(',', '_').replace(' ', '_')}_{analysis_type}_{timestamp}.json"
        
        import json

        # æ®µéšçš„å¤‰æ›å‡¦ç†
        try:
            print(f"   ğŸ” çµæœå¤‰æ›é–‹å§‹...")
            serializable_results = convert_to_serializable(results)
            print(f"   âœ… çµæœå¤‰æ›å®Œäº†")
            
            # JSONãƒ†ã‚¹ãƒˆ
            json_test = json.dumps(serializable_results)
            print(f"   âœ… JSONå¤‰æ›ãƒ†ã‚¹ãƒˆæˆåŠŸ")
            
        except Exception as convert_error:
            print(f"   âš ï¸ å¤‰æ›ã‚¨ãƒ©ãƒ¼: {convert_error}")
            # ã‚ˆã‚Šå®‰å…¨ãªãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†
            serializable_results = create_safe_fallback_data(results, location, analysis_type, str(convert_error))
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
        with open(output_dir / filename, 'w', encoding='utf-8') as f:
            json.dump(serializable_results, f, ensure_ascii=False, indent=2)
        
        print(f"   ğŸ’¾ çµæœä¿å­˜: {filename}")
        
    except Exception as e:
        logger.warning(f"çµæœã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
        print(f"   âš ï¸ ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆå‡¦ç†ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸãŒã€åˆ†æã¯æ­£å¸¸ã«å®Œäº†ã—ã¦ã„ã¾ã™")


def create_safe_fallback_data(results, location, analysis_type, error_msg):
    """å®‰å…¨ãªãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ"""
    safe_data = {
        "metadata": {
            "location": location,
            "analysis_type": analysis_type,
            "timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
            "export_status": "partial_due_to_serialization_error",
            "error_message": error_msg
        }
    }
    
    # åŸºæœ¬çš„ãªæ•°å€¤ãƒ‡ãƒ¼ã‚¿ã®ã¿æŠ½å‡º
    def extract_safe_data(obj, path=""):
        if isinstance(obj, dict):
            for key, value in obj.items():
                if isinstance(key, (str, int, float, bool)) or key is None:
                    new_path = f"{path}.{key}" if path else str(key)
                    if isinstance(value, (str, int, float, bool)) or value is None:
                        safe_data[new_path] = value
                    elif isinstance(value, dict):
                        extract_safe_data(value, new_path)
                    elif isinstance(value, list) and all(isinstance(item, (str, int, float, bool)) for item in value[:5]):
                        safe_data[new_path] = value[:5]  # æœ€åˆã®5è¦ç´ ã®ã¿
    
    try:
        extract_safe_data(results)
    except Exception:
        safe_data["extraction_error"] = "Failed to extract safe data"
    
    return safe_data


def convert_to_serializable(obj):
    """ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’JSON serializable ã«å¤‰æ›"""
    import networkx as nx  # ãƒ­ãƒ¼ã‚«ãƒ«ã‚¤ãƒ³ãƒãƒ¼ãƒˆè¿½åŠ 
    import numpy as np
    from shapely.geometry.base import BaseGeometry
    
    if isinstance(obj, dict):
        # è¾æ›¸ã®ã‚­ãƒ¼ãŒã‚¿ãƒ—ãƒ«ã®å ´åˆã¯æ–‡å­—åˆ—ã«å¤‰æ›
        converted_dict = {}
        for k, v in obj.items():
            if isinstance(k, tuple):
                # ã‚¿ãƒ—ãƒ«ã‚­ãƒ¼ã‚’æ–‡å­—åˆ—ã«å¤‰æ›
                key_str = f"{k[0]}_{k[1]}" if len(k) == 2 else "_".join(map(str, k))
                converted_dict[key_str] = convert_to_serializable(v)
            elif isinstance(k, (str, int, float, bool)) or k is None:
                converted_dict[k] = convert_to_serializable(v)
            else:
                # ãã®ä»–ã®å‹ã®ã‚­ãƒ¼ã¯æ–‡å­—åˆ—ã«å¤‰æ›
                converted_dict[str(k)] = convert_to_serializable(v)
        return converted_dict
    elif isinstance(obj, list):
        return [convert_to_serializable(item) for item in obj]
    elif isinstance(obj, tuple):
        return list(convert_to_serializable(item) for item in obj)
    elif isinstance(obj, nx.Graph):
        return {"type": "networkx.Graph", "nodes": len(obj.nodes()), "edges": len(obj.edges())}
    elif isinstance(obj, BaseGeometry):
        # Shapelyå¹¾ä½•å­¦ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®å‡¦ç†
        return {
            "type": "shapely_geometry",
            "geometry_type": obj.geom_type,
            "area": getattr(obj, 'area', 0),
            "length": getattr(obj, 'length', 0),
            "bounds": list(obj.bounds) if hasattr(obj, 'bounds') else [],
            "is_valid": obj.is_valid if hasattr(obj, 'is_valid') else True
        }
    elif isinstance(obj, (np.integer, np.floating)):
        return float(obj)
    elif isinstance(obj, np.ndarray):
        return obj.tolist()
    elif hasattr(obj, '__dict__'):
        return {"type": str(type(obj)), "value": str(obj)}
    elif callable(obj):
        return {"type": "callable", "name": getattr(obj, '__name__', 'unknown')}
    else:
        try:
            # åŸºæœ¬çš„ãªJSON serializableã‹ãƒã‚§ãƒƒã‚¯
            import json
            json.dumps(obj)
            return obj
        except (TypeError, ValueError):
            return {"type": str(type(obj)), "value": str(obj)}


def create_comprehensive_charts(results, location):
    """åŒ…æ‹¬çš„ã§æ„å‘³ã®ã‚ã‚‹ãƒãƒ£ãƒ¼ãƒˆã‚»ãƒƒãƒˆã‚’ä½œæˆï¼ˆæ—¥æœ¬èªç‰ˆï¼‰"""
    try:
        import warnings

        import matplotlib.pyplot as plt
        import numpy as np

        # matplotlibè­¦å‘Šã‚’æŠ‘åˆ¶
        warnings.filterwarnings('ignore', category=UserWarning, module='matplotlib')
        
        # æ—¥æœ¬èªéƒ½å¸‚åã‚’å–å¾—
        location_jp = CITY_NAMES_JP.get(location, location)
        
        # åŸºæœ¬åˆ†æçµæœã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
        basic_analysis = results.get('basic_analysis', {})
        major_network = basic_analysis.get('major_network', {})
        axial_analysis = results.get('axial_analysis', {})
        visibility_analysis = results.get('visibility_analysis', {})
        integrated_evaluation = results.get('integrated_evaluation', {})
        
        if not major_network:
            return
        
        # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        output_dir = Path("demo_output")
        base_filename = f"analysis_{location.replace(',', '_').replace(' ', '_')}"
        
        # 1. ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯åŸºæœ¬æŒ‡æ¨™ãƒãƒ£ãƒ¼ãƒˆ
        create_network_metrics_chart_jp(major_network, location_jp, output_dir, base_filename)
        
        # 2. Space SyntaxæŒ‡æ¨™ãƒãƒ£ãƒ¼ãƒˆ
        create_space_syntax_chart_jp(major_network, location_jp, output_dir, base_filename)
        
        # 3. è»¸ç·šåˆ†æçµæœãƒãƒ£ãƒ¼ãƒˆ
        if axial_analysis and not axial_analysis.get('error'):
            create_axial_analysis_chart_jp(axial_analysis, location_jp, output_dir, base_filename)
        
        # 4. çµ±åˆè©•ä¾¡ãƒãƒ£ãƒ¼ãƒˆ
        if integrated_evaluation and not integrated_evaluation.get('error'):
            create_integrated_evaluation_chart_jp(integrated_evaluation, location_jp, output_dir, base_filename)
        
        # 5. åŒ…æ‹¬çš„ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰
        create_comprehensive_dashboard_jp(results, location_jp, output_dir, base_filename)
        
        print(f"   ğŸ“Š åŒ…æ‹¬çš„ãƒãƒ£ãƒ¼ãƒˆã‚»ãƒƒãƒˆç”Ÿæˆå®Œäº† ({location_jp})")
        
    except Exception as e:
        logger.debug(f"åŒ…æ‹¬çš„ãƒãƒ£ãƒ¼ãƒˆä½œæˆã‚¨ãƒ©ãƒ¼: {e}")
        pass


def create_network_metrics_chart_jp(major_network, location_jp, output_dir, base_filename):
    """ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯åŸºæœ¬æŒ‡æ¨™ãƒãƒ£ãƒ¼ãƒˆï¼ˆæ—¥æœ¬èªç‰ˆï¼‰"""
    try:
        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(12, 10))
        fig.suptitle(f'{location_jp} - ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯åŸºæœ¬æŒ‡æ¨™', fontsize=14, fontweight='bold')
        
        # 1. ãƒãƒ¼ãƒ‰ãƒ»ã‚¨ãƒƒã‚¸æ•°
        counts = [major_network.get('node_count', 0), major_network.get('edge_count', 0)]
        labels = ['ãƒãƒ¼ãƒ‰æ•°', 'ã‚¨ãƒƒã‚¸æ•°']
        colors = ['#2E86AB', '#A23B72']
        
        ax1.bar(labels, counts, color=colors)
        ax1.set_title('ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯è¦æ¨¡', fontweight='bold')
        ax1.set_ylabel('æ•°é‡')
        for i, v in enumerate(counts):
            ax1.text(i, v + max(counts)*0.01, f'{v:,}', ha='center', va='bottom')
        
        # 2. æ¥ç¶šæ€§æŒ‡æ¨™
        connectivity = {
            'å¹³å‡æ¬¡æ•°': major_network.get('avg_degree', 0),
            'æœ€å¤§æ¬¡æ•°': major_network.get('max_degree', 0),
            'å¯†åº¦Ã—1000': major_network.get('density', 0) * 1000  # ã‚¹ã‚±ãƒ¼ãƒ«èª¿æ•´
        }
        
        ax2.bar(connectivity.keys(), connectivity.values(), color='#F18F01')
        ax2.set_title('æ¥ç¶šæ€§æŒ‡æ¨™', fontweight='bold')
        ax2.set_ylabel('å€¤')
        ax2.tick_params(axis='x', rotation=45)
        
        # 3. Space SyntaxåŸºæœ¬æŒ‡æ¨™
        syntax_metrics = {
            'Î±æŒ‡æ•°': major_network.get('alpha_index', 0),
            'Î²æŒ‡æ•°': major_network.get('beta_index', 0),
            'Î³æŒ‡æ•°': major_network.get('gamma_index', 0)
        }
        
        ax3.bar(syntax_metrics.keys(), syntax_metrics.values(), color='#C73E1D')
        ax3.set_title('Space Syntax æŒ‡æ¨™', fontweight='bold')
        ax3.set_ylabel('å€¤')
        
        # 4. åŠ¹ç‡æ€§æŒ‡æ¨™
        efficiency_data = {
            'é“è·¯å¯†åº¦\n(km/kmÂ²)': major_network.get('road_density', 0),
            'å¹³å‡è¿‚å›ç‡': major_network.get('avg_circuity', 0),
            'é€£çµæˆåˆ†æ•°': major_network.get('num_components', 0)
        }
        
        ax4.bar(efficiency_data.keys(), efficiency_data.values(), color='#3F7D20')
        ax4.set_title('åŠ¹ç‡æ€§æŒ‡æ¨™', fontweight='bold')
        ax4.set_ylabel('å€¤')
        ax4.tick_params(axis='x', rotation=45)
        
        plt.tight_layout()
        chart_file = output_dir / f"{base_filename}_network_metrics.png"
        plt.savefig(chart_file, dpi=150, bbox_inches='tight')
        plt.close()
        
        print(f"   ğŸ“Š ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æŒ‡æ¨™ãƒãƒ£ãƒ¼ãƒˆ: {chart_file.name}")
        
    except Exception as e:
        logger.debug(f"ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æŒ‡æ¨™ãƒãƒ£ãƒ¼ãƒˆä½œæˆã‚¨ãƒ©ãƒ¼: {e}")


def create_space_syntax_chart_jp(major_network, location_jp, output_dir, base_filename):
    """Space Syntaxå°‚ç”¨ãƒãƒ£ãƒ¼ãƒˆï¼ˆæ—¥æœ¬èªç‰ˆï¼‰"""
    try:
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))
        fig.suptitle(f'{location_jp} - Space Syntax åˆ†æ', fontsize=14, fontweight='bold')
        
        # 1. æŒ‡æ¨™å€¤ã®æ£’ã‚°ãƒ©ãƒ•
        indices = {
            'Î±æŒ‡æ•°': major_network.get('alpha_index', 0),
            'Î²æŒ‡æ•°': major_network.get('beta_index', 0), 
            'Î³æŒ‡æ•°': major_network.get('gamma_index', 0)
        }
        
        colors = ['#FF6B6B', '#4ECDC4', '#45B7D1']
        bars = ax1.bar(indices.keys(), indices.values(), color=colors)
        ax1.set_title('Space Syntax æŒ‡æ¨™å€¤', fontweight='bold')
        ax1.set_ylabel('æŒ‡æ¨™å€¤')
        
        # å€¤ã‚’ãƒãƒ¼ã®ä¸Šã«è¡¨ç¤º
        for bar, value in zip(bars, indices.values()):
            ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5, 
                    f'{value:.2f}', ha='center', va='bottom')
        
        # 2. ç†è«–çš„åŸºæº–ã¨ã®æ¯”è¼ƒï¼ˆå††ã‚°ãƒ©ãƒ•ï¼‰
        categories = ['Î±æŒ‡æ•°\n(å¾ªç’°æ€§)', 'Î²æŒ‡æ•°\n(è¤‡é›‘æ€§)', 'Î³æŒ‡æ•°\n(æ¥ç¶šæ€§)']
        values = [
            min(major_network.get('alpha_index', 0) / 50 * 100, 100),  # æ­£è¦åŒ–
            min(major_network.get('beta_index', 0) / 3 * 100, 100),
            min(major_network.get('gamma_index', 0) / 1 * 100, 100)
        ]
        
        # å††ã‚°ãƒ©ãƒ•ã¨ã—ã¦è¡¨ç¤º
        ax2.pie(values, labels=categories, autopct='%1.1f%%', startangle=90, 
                colors=['#FF6B6B', '#4ECDC4', '#45B7D1'])
        ax2.set_title('ç›¸å¯¾çš„åˆ†å¸ƒ', fontweight='bold')
        
        plt.tight_layout()
        chart_file = output_dir / f"{base_filename}_space_syntax.png"
        plt.savefig(chart_file, dpi=150, bbox_inches='tight')
        plt.close()
        
        print(f"   ğŸ“Š Space Syntax ãƒãƒ£ãƒ¼ãƒˆ: {chart_file.name}")
        
    except Exception as e:
        logger.debug(f"Space Syntaxãƒãƒ£ãƒ¼ãƒˆä½œæˆã‚¨ãƒ©ãƒ¼: {e}")


def create_axial_analysis_chart_jp(axial_analysis, location_jp, output_dir, base_filename):
    """è»¸ç·šåˆ†æå°‚ç”¨ãƒãƒ£ãƒ¼ãƒˆï¼ˆæ—¥æœ¬èªç‰ˆï¼‰"""
    try:
        network_metrics = axial_analysis.get('network_metrics', {})
        integration_stats = axial_analysis.get('integration_statistics', {})
        
        if not network_metrics and not integration_stats:
            return
        
        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(12, 10))
        fig.suptitle(f'{location_jp} - è»¸ç·šåˆ†æçµæœ', fontsize=14, fontweight='bold')
        
        # 1. è»¸ç·šãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æŒ‡æ¨™
        if network_metrics:
            axial_data = {
                'è»¸ç·šæ•°': network_metrics.get('axial_lines', 0),
                'æ¥ç¶šæ•°': network_metrics.get('axial_connections', 0),
                'å­¤ç«‹æ•°': network_metrics.get('axial_islands', 0)
            }
            
            ax1.bar(axial_data.keys(), axial_data.values(), color='#8E44AD')
            ax1.set_title('è»¸ç·šãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ§‹é€ ', fontweight='bold')
            ax1.set_ylabel('æ•°é‡')
            ax1.tick_params(axis='x', rotation=45)
            
            # å€¤ã‚’ãƒãƒ¼ã®ä¸Šã«è¡¨ç¤º
            for i, (k, v) in enumerate(axial_data.items()):
                ax1.text(i, v + max(axial_data.values())*0.01, f'{v:,}', ha='center', va='bottom')
        
        # 2. å½¢æ…‹æŒ‡æ¨™
        if network_metrics:
            morphology = {
                'æ ¼å­è»¸æ€§': network_metrics.get('grid_axiality', 0) * 1000,  # ã‚¹ã‚±ãƒ¼ãƒ«èª¿æ•´
                'è»¸ç·šç’°çŠ¶æ€§': network_metrics.get('axial_ringiness', 0),
                'é–¢ç¯€æ€§': network_metrics.get('axial_articulation', 0) * 100  # ãƒ‘ãƒ¼ã‚»ãƒ³ãƒˆè¡¨ç¤º
            }
            
            ax2.bar(morphology.keys(), morphology.values(), color='#27AE60')
            ax2.set_title('å½¢æ…‹å­¦çš„æŒ‡æ¨™', fontweight='bold')
            ax2.set_ylabel('æ­£è¦åŒ–å€¤')
            ax2.tick_params(axis='x', rotation=45)
        
        # 3. çµ±åˆå€¤çµ±è¨ˆ
        if integration_stats:
            stats_data = {
                'å¹³å‡': integration_stats.get('mean', 0),
                'æ¨™æº–åå·®': integration_stats.get('std', 0),
                'ä¸­å¤®å€¤': integration_stats.get('median', 0)
            }
            
            ax3.bar(stats_data.keys(), stats_data.values(), color='#E74C3C')
            ax3.set_title('çµ±åˆå€¤çµ±è¨ˆ', fontweight='bold')
            ax3.set_ylabel('çµ±åˆå€¤')
            
            # å€¤ã‚’ãƒãƒ¼ã®ä¸Šã«è¡¨ç¤º
            for i, (k, v) in enumerate(stats_data.items()):
                ax3.text(i, v + 0.01, f'{v:.3f}', ha='center', va='bottom')
        
        # 4. çµ±åˆå€¤åˆ†å¸ƒï¼ˆç†è«–çš„åˆ†å¸ƒï¼‰
        if integration_stats:
            mean = integration_stats.get('mean', 0)
            std = integration_stats.get('std', 0)
            min_val = integration_stats.get('min', 0)
            max_val = integration_stats.get('max', 0)
            
            # ç†è«–çš„åˆ†å¸ƒã‚’è¡¨ç¤º
            x = np.linspace(min_val, max_val, 100)
            y = np.exp(-0.5 * ((x - mean) / std) ** 2) if std > 0 else np.ones_like(x)
            
            ax4.plot(x, y, 'b-', linewidth=2, label='åˆ†å¸ƒå½¢çŠ¶')
            ax4.axvline(mean, color='r', linestyle='--', label=f'å¹³å‡: {mean:.3f}')
            ax4.axvline(min_val, color='g', linestyle=':', label=f'æœ€å°: {min_val:.3f}')
            ax4.axvline(max_val, color='g', linestyle=':', label=f'æœ€å¤§: {max_val:.3f}')
            
            ax4.set_title('çµ±åˆå€¤åˆ†å¸ƒ', fontweight='bold')
            ax4.set_xlabel('çµ±åˆå€¤')
            ax4.set_ylabel('ç›¸å¯¾é »åº¦')
            ax4.legend()
        
        plt.tight_layout()
        chart_file = output_dir / f"{base_filename}_axial_analysis.png"
        plt.savefig(chart_file, dpi=150, bbox_inches='tight')
        plt.close()
        
        print(f"   ğŸ“Š è»¸ç·šåˆ†æãƒãƒ£ãƒ¼ãƒˆ: {chart_file.name}")
        
    except Exception as e:
        logger.debug(f"è»¸ç·šåˆ†æãƒãƒ£ãƒ¼ãƒˆä½œæˆã‚¨ãƒ©ãƒ¼: {e}")


def create_integrated_evaluation_chart_jp(evaluation, location_jp, output_dir, base_filename):
    """çµ±åˆè©•ä¾¡ãƒãƒ£ãƒ¼ãƒˆï¼ˆæ—¥æœ¬èªç‰ˆï¼‰"""
    try:
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))
        fig.suptitle(f'{location_jp} - çµ±åˆè©•ä¾¡', fontsize=14, fontweight='bold')
        
        # 1. ã‚¹ã‚³ã‚¢æ¯”è¼ƒ
        scores = {
            'å›éŠæ€§': evaluation.get('connectivity_score', 0),
            'ã‚¢ã‚¯ã‚»ã‚¹æ€§': evaluation.get('accessibility_score', 0),
            'åŠ¹ç‡æ€§': evaluation.get('efficiency_score', 0),
            'ç·åˆ': evaluation.get('overall_score', 0)
        }
        
        colors = ['#3498DB', '#2ECC71', '#F39C12', '#E74C3C']
        bars = ax1.bar(scores.keys(), scores.values(), color=colors)
        ax1.set_title('ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚¹ã‚³ã‚¢', fontweight='bold')
        ax1.set_ylabel('ã‚¹ã‚³ã‚¢ (0-100)')
        ax1.set_ylim(0, 100)
        ax1.tick_params(axis='x', rotation=45)
        
        # ã‚¹ã‚³ã‚¢ãƒãƒ¼ã«å€¤ã‚’è¡¨ç¤º
        for bar, value in zip(bars, scores.values()):
            ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1, 
                    f'{value:.1f}', ha='center', va='bottom')
        
        # 2. ãƒ¬ãƒ¼ãƒ€ãƒ¼ãƒãƒ£ãƒ¼ãƒˆ
        angles = np.linspace(0, 2 * np.pi, len(scores), endpoint=False).tolist()
        values = list(scores.values())
        
        # ãƒ¬ãƒ¼ãƒ€ãƒ¼ãƒãƒ£ãƒ¼ãƒˆã‚’å††å½¢ã«é–‰ã˜ã‚‹
        angles += angles[:1]
        values += values[:1]
        
        ax2 = plt.subplot(122, projection='polar')
        ax2.plot(angles, values, 'o-', linewidth=2, color='#E74C3C')
        ax2.fill(angles, values, alpha=0.25, color='#E74C3C')
        ax2.set_xticks(angles[:-1])
        ax2.set_xticklabels(scores.keys())
        ax2.set_ylim(0, 100)
        ax2.set_title('ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ ãƒ¬ãƒ¼ãƒ€ãƒ¼', fontweight='bold', pad=20)
        
        # è©•ä¾¡ãƒ¬ãƒ™ãƒ«ã‚’è¡¨ç¤º
        evaluation_level = evaluation.get('evaluation_level', 'ä¸æ˜')
        fig.text(0.5, 0.02, f'è©•ä¾¡ãƒ¬ãƒ™ãƒ«: {evaluation_level}', 
                ha='center', va='bottom', fontsize=12, fontweight='bold')
        
        plt.tight_layout()
        chart_file = output_dir / f"{base_filename}_evaluation.png"
        plt.savefig(chart_file, dpi=150, bbox_inches='tight')
        plt.close()
        
        print(f"   ğŸ“Š çµ±åˆè©•ä¾¡ãƒãƒ£ãƒ¼ãƒˆ: {chart_file.name}")
        
    except Exception as e:
        logger.debug(f"çµ±åˆè©•ä¾¡ãƒãƒ£ãƒ¼ãƒˆä½œæˆã‚¨ãƒ©ãƒ¼: {e}")


def create_comprehensive_dashboard_jp(results, location_jp, output_dir, base_filename):
    """åŒ…æ‹¬çš„ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ï¼ˆæ—¥æœ¬èªç‰ˆï¼‰"""
    try:
        fig = plt.figure(figsize=(16, 12))
        gs = fig.add_gridspec(3, 4, hspace=0.3, wspace=0.3)
        fig.suptitle(f'{location_jp} - åŒ…æ‹¬çš„ Space Syntax åˆ†æãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰', 
                     fontsize=16, fontweight='bold')
        
        basic_analysis = results.get('basic_analysis', {})
        major_network = basic_analysis.get('major_network', {})
        axial_analysis = results.get('axial_analysis', {})
        integrated_evaluation = results.get('integrated_evaluation', {})
        
        # 1. ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ¦‚è¦ (å·¦ä¸Š)
        ax1 = fig.add_subplot(gs[0, :2])
        network_summary = {
            'ãƒãƒ¼ãƒ‰': major_network.get('node_count', 0),
            'ã‚¨ãƒƒã‚¸': major_network.get('edge_count', 0)
        }
        ax1.bar(network_summary.keys(), network_summary.values(), color=['#3498DB', '#2ECC71'])
        ax1.set_title('ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯è¦æ¨¡', fontweight='bold')
        ax1.set_ylabel('æ•°é‡')
        
        # 2. Space SyntaxæŒ‡æ¨™ (å³ä¸Š)
        ax2 = fig.add_subplot(gs[0, 2:])
        syntax_indices = {
            'Î±æŒ‡æ•°': major_network.get('alpha_index', 0),
            'Î²æŒ‡æ•°': major_network.get('beta_index', 0),
            'Î³æŒ‡æ•°': major_network.get('gamma_index', 0)
        }
        ax2.bar(syntax_indices.keys(), syntax_indices.values(), color=['#E74C3C', '#F39C12', '#9B59B6'])
        ax2.set_title('Space Syntax æŒ‡æ¨™', fontweight='bold')
        ax2.set_ylabel('æŒ‡æ¨™å€¤')
        
        # 3. è»¸ç·šåˆ†æ (ä¸­æ®µå·¦)
        ax3 = fig.add_subplot(gs[1, :2])
        if axial_analysis and not axial_analysis.get('error'):
            network_metrics = axial_analysis.get('network_metrics', {})
            axial_data = {
                'è»¸ç·š': network_metrics.get('axial_lines', 0),
                'æ¥ç¶š': network_metrics.get('axial_connections', 0)
            }
            ax3.bar(axial_data.keys(), axial_data.values(), color=['#8E44AD', '#27AE60'])
            ax3.set_title('è»¸ç·šåˆ†æ', fontweight='bold')
            ax3.set_ylabel('æ•°é‡')
        else:
            ax3.text(0.5, 0.5, 'è»¸ç·šåˆ†æ\nåˆ©ç”¨ä¸å¯', ha='center', va='center', 
                    transform=ax3.transAxes, fontsize=12)
        
        # 4. çµ±åˆå€¤çµ±è¨ˆ (ä¸­æ®µå³)
        ax4 = fig.add_subplot(gs[1, 2:])
        if axial_analysis and not axial_analysis.get('error'):
            integration_stats = axial_analysis.get('integration_statistics', {})
            if integration_stats:
                stats = {
                    'å¹³å‡': integration_stats.get('mean', 0),
                    'æ¨™æº–åå·®': integration_stats.get('std', 0),
                    'æœ€å¤§': integration_stats.get('max', 0)
                }
                ax4.bar(stats.keys(), stats.values(), color=['#E67E22', '#D35400', '#C0392B'])
                ax4.set_title('çµ±åˆå€¤çµ±è¨ˆ', fontweight='bold')
                ax4.set_ylabel('å€¤')
        
        # 5. çµ±åˆè©•ä¾¡ (ä¸‹æ®µ)
        ax5 = fig.add_subplot(gs[2, :])
        if integrated_evaluation and not integrated_evaluation.get('error'):
            eval_scores = {
                'å›éŠæ€§': integrated_evaluation.get('connectivity_score', 0),
                'ã‚¢ã‚¯ã‚»ã‚¹æ€§': integrated_evaluation.get('accessibility_score', 0),
                'åŠ¹ç‡æ€§': integrated_evaluation.get('efficiency_score', 0),
                'ç·åˆ': integrated_evaluation.get('overall_score', 0)
            }
            
            colors = ['#3498DB', '#2ECC71', '#F39C12', '#E74C3C']
            bars = ax5.bar(eval_scores.keys(), eval_scores.values(), color=colors)
            ax5.set_title('çµ±åˆè©•ä¾¡ã‚¹ã‚³ã‚¢', fontweight='bold')
            ax5.set_ylabel('ã‚¹ã‚³ã‚¢ (0-100)')
            ax5.set_ylim(0, 100)
            
            # è©•ä¾¡ãƒ¬ãƒ™ãƒ«ã‚’ãƒ†ã‚­ã‚¹ãƒˆã§è¡¨ç¤º
            evaluation_level = integrated_evaluation.get('evaluation_level', 'ä¸æ˜')
            ax5.text(0.98, 0.95, f'ãƒ¬ãƒ™ãƒ«: {evaluation_level}', transform=ax5.transAxes, 
                    ha='right', va='top', fontsize=10, fontweight='bold',
                    bbox=dict(boxstyle='round', facecolor='lightgray', alpha=0.7))
        
        plt.tight_layout()
        chart_file = output_dir / f"{base_filename}_dashboard.png"
        plt.savefig(chart_file, dpi=150, bbox_inches='tight')
        plt.close()
        
        print(f"   ğŸ“Š åŒ…æ‹¬çš„ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰: {chart_file.name}")
        
    except Exception as e:
        logger.debug(f"ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ä½œæˆã‚¨ãƒ©ãƒ¼: {e}")


def try_visualization(analyzer, results, location, analysis_type):
    """æ”¹å–„ã•ã‚ŒãŸå¯è¦–åŒ–ã®è©¦è¡Œ"""
    try:
        print(f"   ğŸ“ˆ å¯è¦–åŒ–ç”Ÿæˆä¸­...")
        
        # åŒ…æ‹¬çš„ãƒãƒ£ãƒ¼ãƒˆã‚»ãƒƒãƒˆã‚’ä½œæˆ
        create_comprehensive_charts(results, location)
        
        print(f"   ğŸ“ˆ å¯è¦–åŒ–å®Œäº†")
        
    except Exception as e:
        logger.warning(f"å¯è¦–åŒ–ã‚¨ãƒ©ãƒ¼: {e}")
        print(f"   âš ï¸ å¯è¦–åŒ–ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã—ãŸ")


def generate_comparative_report(successful_analyses):
    """éƒ½å¸‚é–“æ¯”è¼ƒåˆ†æãƒ¬ãƒãƒ¼ãƒˆã‚’ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³å½¢å¼ã§ç”Ÿæˆ"""
    try:
        output_dir = Path("demo_output")
        output_dir.mkdir(exist_ok=True)
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        report_file = output_dir / f"comparative_analysis_report_{timestamp}.md"
        
        with open(report_file, 'w', encoding='utf-8') as f:
            # ãƒ¬ãƒãƒ¼ãƒˆãƒ˜ãƒƒãƒ€ãƒ¼
            f.write("# é•·é‡çœŒä¸»è¦éƒ½å¸‚ Space Syntax æ¯”è¼ƒåˆ†æãƒ¬ãƒãƒ¼ãƒˆ\n\n")
            f.write(f"**ç”Ÿæˆæ—¥æ™‚**: {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')}\n\n")
            f.write("## ğŸ“‹ åˆ†æå¯¾è±¡éƒ½å¸‚\n\n")
            
            analyzed_cities = []
            for location, results, analysis_type, execution_time in successful_analyses:
                city_jp = CITY_NAMES_JP.get(location, location)
                analyzed_cities.append(city_jp)
                f.write(f"- **{city_jp}** ({location})\n")
            
            f.write(f"\n**åˆ†æéƒ½å¸‚æ•°**: {len(analyzed_cities)}éƒ½å¸‚\n\n")
            
            # å®Ÿè¡Œæ¦‚è¦
            f.write("## âš¡ å®Ÿè¡Œæ¦‚è¦\n\n")
            f.write("| éƒ½å¸‚ | åˆ†æã‚¿ã‚¤ãƒ— | å®Ÿè¡Œæ™‚é–“ | ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ |\n")
            f.write("|------|------------|----------|------------|\n")
            
            for location, results, analysis_type, execution_time in successful_analyses:
                city_jp = CITY_NAMES_JP.get(location, location)
                status = "âœ… æˆåŠŸ" if not results.get('error', False) else "âŒ ã‚¨ãƒ©ãƒ¼"
                f.write(f"| {city_jp} | {analysis_type} | {execution_time:.1f}ç§’ | {status} |\n")
            
            # åŸºæœ¬ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æŒ‡æ¨™æ¯”è¼ƒ
            f.write("\n## ğŸ“Š åŸºæœ¬ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æŒ‡æ¨™æ¯”è¼ƒ\n\n")
            f.write("### ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯è¦æ¨¡\n\n")
            f.write("| éƒ½å¸‚ | ãƒãƒ¼ãƒ‰æ•° | ã‚¨ãƒƒã‚¸æ•° | å¹³å‡æ¬¡æ•° | æœ€å¤§æ¬¡æ•° | å¯†åº¦ |\n")
            f.write("|------|----------|----------|----------|----------|------|\n")
            
            # ãƒ‡ãƒ¼ã‚¿åé›†ã¨è¡¨ç¤º
            network_data = {}
            for location, results, analysis_type, execution_time in successful_analyses:
                city_jp = CITY_NAMES_JP.get(location, location)
                basic_analysis = results.get('basic_analysis', {})
                major_network = basic_analysis.get('major_network', {})
                
                network_data[city_jp] = {
                    'node_count': major_network.get('node_count', 0),
                    'edge_count': major_network.get('edge_count', 0),
                    'avg_degree': major_network.get('avg_degree', 0),
                    'max_degree': major_network.get('max_degree', 0),
                    'density': major_network.get('density', 0),
                    'alpha_index': major_network.get('alpha_index', 0),
                    'beta_index': major_network.get('beta_index', 0),
                    'gamma_index': major_network.get('gamma_index', 0),
                    'road_density': major_network.get('road_density', 0),
                    'avg_circuity': major_network.get('avg_circuity', 0)
                }
                
                f.write(f"| {city_jp} | {major_network.get('node_count', 0):,} | "
                       f"{major_network.get('edge_count', 0):,} | "
                       f"{major_network.get('avg_degree', 0):.2f} | "
                       f"{major_network.get('max_degree', 0)} | "
                       f"{major_network.get('density', 0):.6f} |\n")
            
            # Space Syntax æŒ‡æ¨™æ¯”è¼ƒ
            f.write("\n### Space Syntax æŒ‡æ¨™\n\n")
            f.write("| éƒ½å¸‚ | Î±æŒ‡æ•° | Î²æŒ‡æ•° | Î³æŒ‡æ•° | é“è·¯å¯†åº¦ (km/kmÂ²) | å¹³å‡è¿‚å›ç‡ |\n")
            f.write("|------|-------|-------|-------|------------------|------------|\n")
            
            for location, results, analysis_type, execution_time in successful_analyses:
                city_jp = CITY_NAMES_JP.get(location, location)
                basic_analysis = results.get('basic_analysis', {})
                major_network = basic_analysis.get('major_network', {})
                
                f.write(f"| {city_jp} | "
                       f"{major_network.get('alpha_index', 0):.2f} | "
                       f"{major_network.get('beta_index', 0):.2f} | "
                       f"{major_network.get('gamma_index', 0):.2f} | "
                       f"{major_network.get('road_density', 0):.2f} | "
                       f"{major_network.get('avg_circuity', 0):.2f} |\n")
            
            # çµ±åˆè©•ä¾¡æ¯”è¼ƒï¼ˆæ‹¡å¼µåˆ†æãŒã‚ã‚‹å ´åˆï¼‰
            has_integrated_evaluation = any(
                results.get('integrated_evaluation') and not results.get('integrated_evaluation', {}).get('error')
                for _, results, _, _ in successful_analyses
            )
            
            if has_integrated_evaluation:
                f.write("\n## ğŸ¯ çµ±åˆè©•ä¾¡æ¯”è¼ƒ\n\n")
                f.write("| éƒ½å¸‚ | å›éŠæ€§ | ã‚¢ã‚¯ã‚»ã‚¹æ€§ | åŠ¹ç‡æ€§ | ç·åˆã‚¹ã‚³ã‚¢ | è©•ä¾¡ãƒ¬ãƒ™ãƒ« |\n")
                f.write("|------|--------|------------|--------|------------|------------|\n")
                
                for location, results, analysis_type, execution_time in successful_analyses:
                    city_jp = CITY_NAMES_JP.get(location, location)
                    integrated_evaluation = results.get('integrated_evaluation', {})
                    
                    if integrated_evaluation and not integrated_evaluation.get('error'):
                        f.write(f"| {city_jp} | "
                               f"{integrated_evaluation.get('connectivity_score', 0):.1f} | "
                               f"{integrated_evaluation.get('accessibility_score', 0):.1f} | "
                               f"{integrated_evaluation.get('efficiency_score', 0):.1f} | "
                               f"{integrated_evaluation.get('overall_score', 0):.1f} | "
                               f"{integrated_evaluation.get('evaluation_level', 'ä¸æ˜')} |\n")
                    else:
                        f.write(f"| {city_jp} | - | - | - | - | è©•ä¾¡ä¸å¯ |\n")
            
            # æ¯”è¼ƒåˆ†æã¨è€ƒå¯Ÿ
            f.write("\n## ğŸ” æ¯”è¼ƒåˆ†æã¨è€ƒå¯Ÿ\n\n")
            
            # ãƒ©ãƒ³ã‚­ãƒ³ã‚°åˆ†æ
            f.write("### ä¸»è¦æŒ‡æ¨™ãƒ©ãƒ³ã‚­ãƒ³ã‚°\n\n")
            
            # ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯è¦æ¨¡ãƒ©ãƒ³ã‚­ãƒ³ã‚°
            if network_data:
                size_ranking = sorted(network_data.items(), 
                                    key=lambda x: x[1]['node_count'], reverse=True)
                f.write("#### ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯è¦æ¨¡ (ãƒãƒ¼ãƒ‰æ•°)\n")
                for i, (city, data) in enumerate(size_ranking, 1):
                    f.write(f"{i}. **{city}**: {data['node_count']:,}ãƒãƒ¼ãƒ‰\n")
                
                # Î±æŒ‡æ•°ãƒ©ãƒ³ã‚­ãƒ³ã‚°ï¼ˆå¾ªç’°æ€§ï¼‰
                alpha_ranking = sorted(network_data.items(), 
                                     key=lambda x: x[1]['alpha_index'], reverse=True)
                f.write("\n#### å¾ªç’°æ€§ (Î±æŒ‡æ•°)\n")
                for i, (city, data) in enumerate(alpha_ranking, 1):
                    f.write(f"{i}. **{city}**: {data['alpha_index']:.2f}\n")
                
                # é“è·¯å¯†åº¦ãƒ©ãƒ³ã‚­ãƒ³ã‚°
                density_ranking = sorted(network_data.items(), 
                                       key=lambda x: x[1]['road_density'], reverse=True)
                f.write("\n#### é“è·¯å¯†åº¦\n")
                for i, (city, data) in enumerate(density_ranking, 1):
                    f.write(f"{i}. **{city}**: {data['road_density']:.2f} km/kmÂ²\n")
                
                # åŠ¹ç‡æ€§ãƒ©ãƒ³ã‚­ãƒ³ã‚°ï¼ˆè¿‚å›ç‡ã®é€†é †ï¼‰
                efficiency_ranking = sorted(network_data.items(), 
                                          key=lambda x: x[1]['avg_circuity'])
                f.write("\n#### é“è·¯åŠ¹ç‡æ€§ (ä½è¿‚å›ç‡é †)\n")
                for i, (city, data) in enumerate(efficiency_ranking, 1):
                    f.write(f"{i}. **{city}**: {data['avg_circuity']:.2f}\n")
            
            # éƒ½å¸‚ç‰¹æ€§åˆ†æ
            f.write("\n### éƒ½å¸‚ç‰¹æ€§åˆ†æ\n\n")
            
            for location, results, analysis_type, execution_time in successful_analyses:
                city_jp = CITY_NAMES_JP.get(location, location)
                basic_analysis = results.get('basic_analysis', {})
                major_network = basic_analysis.get('major_network', {})
                
                f.write(f"#### {city_jp}\n\n")
                
                # åŸºæœ¬ç‰¹æ€§
                node_count = major_network.get('node_count', 0)
                edge_count = major_network.get('edge_count', 0)
                alpha_index = major_network.get('alpha_index', 0)
                gamma_index = major_network.get('gamma_index', 0)
                road_density = major_network.get('road_density', 0)
                avg_circuity = major_network.get('avg_circuity', 0)
                
                f.write(f"**åŸºæœ¬ç‰¹æ€§**:\n")
                f.write(f"- ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯è¦æ¨¡: {node_count:,}ãƒãƒ¼ãƒ‰, {edge_count:,}ã‚¨ãƒƒã‚¸\n")
                f.write(f"- é“è·¯å¯†åº¦: {road_density:.2f} km/kmÂ²\n")
                f.write(f"- å¹³å‡è¿‚å›ç‡: {avg_circuity:.2f}\n\n")
                
                # éƒ½å¸‚æ§‹é€ ã®ç‰¹å¾´åˆ†æ
                f.write(f"**éƒ½å¸‚æ§‹é€ ã®ç‰¹å¾´**:\n")
                
                # Î±æŒ‡æ•°ã«ã‚ˆã‚‹å¾ªç’°æ€§è©•ä¾¡
                if alpha_index > 30:
                    circulation = "é«˜ã„å¾ªç’°æ€§ - å¤šãã®ç’°çŠ¶è·¯ãŒã‚ã‚‹è¤‡é›‘ãªé“è·¯ç¶²"
                elif alpha_index > 15:
                    circulation = "ä¸­ç¨‹åº¦ã®å¾ªç’°æ€§ - ãƒãƒ©ãƒ³ã‚¹ã®å–ã‚ŒãŸé“è·¯æ§‹é€ "
                else:
                    circulation = "ä½ã„å¾ªç’°æ€§ - æ¨¹çŠ¶æ§‹é€ ãŒä¸»ä½“ã®é“è·¯ç¶²"
                f.write(f"- å¾ªç’°æ€§ (Î±={alpha_index:.1f}): {circulation}\n")
                
                # Î³æŒ‡æ•°ã«ã‚ˆã‚‹æ¥ç¶šæ€§è©•ä¾¡
                if gamma_index > 0.7:
                    connectivity = "é«˜ã„æ¥ç¶šæ€§ - å¯†ãªé“è·¯ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯"
                elif gamma_index > 0.5:
                    connectivity = "ä¸­ç¨‹åº¦ã®æ¥ç¶šæ€§ - æ¨™æº–çš„ãªé“è·¯å¯†åº¦"
                else:
                    connectivity = "ä½ã„æ¥ç¶šæ€§ - ç–ãªé“è·¯ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯"
                f.write(f"- æ¥ç¶šæ€§ (Î³={gamma_index:.2f}): {connectivity}\n")
                
                # é“è·¯å¯†åº¦ã«ã‚ˆã‚‹éƒ½å¸‚åŒ–åº¦è©•ä¾¡
                if road_density > 15:
                    urbanization = "é«˜å¯†åº¦éƒ½å¸‚éƒ¨ - é«˜åº¦ã«éƒ½å¸‚åŒ–ã•ã‚ŒãŸåœ°åŸŸ"
                elif road_density > 8:
                    urbanization = "ä¸­å¯†åº¦å¸‚è¡—åœ° - é©åº¦ã«ç™ºé”ã—ãŸå¸‚è¡—åœ°"
                else:
                    urbanization = "ä½å¯†åº¦åœ°åŸŸ - éƒŠå¤–ã¾ãŸã¯åœ°æ–¹éƒ½å¸‚ç‰¹æ€§"
                f.write(f"- éƒ½å¸‚åŒ–åº¦: {urbanization}\n")
                
                # è¿‚å›ç‡ã«ã‚ˆã‚‹åŠ¹ç‡æ€§è©•ä¾¡
                if avg_circuity < 1.1:
                    efficiency = "éå¸¸ã«åŠ¹ç‡çš„ - ç›´ç·šçš„ãªé“è·¯æ§‹é€ "
                elif avg_circuity < 1.3:
                    efficiency = "åŠ¹ç‡çš„ - æ¯”è¼ƒçš„ç›´ç·šçš„ãªç§»å‹•ãŒå¯èƒ½"
                elif avg_circuity < 1.5:
                    efficiency = "æ¨™æº–çš„åŠ¹ç‡æ€§ - ä¸€èˆ¬çš„ãªè¿‚å›ãƒ¬ãƒ™ãƒ«"
                else:
                    efficiency = "éåŠ¹ç‡çš„ - è¿‚å›ãŒå¤šã„è¤‡é›‘ãªé“è·¯æ§‹é€ "
                f.write(f"- ç§»å‹•åŠ¹ç‡æ€§: {efficiency}\n\n")
            
            # éƒ½å¸‚é–“æ¯”è¼ƒã«ã‚ˆã‚‹ç·åˆè€ƒå¯Ÿ
            f.write("\n### ç·åˆè€ƒå¯Ÿ\n\n")
            
            if network_data:
                # æœ€å¤§ãƒ»æœ€å°å€¤ã®éƒ½å¸‚ã‚’ç‰¹å®š
                max_alpha_city = max(network_data.items(), key=lambda x: x[1]['alpha_index'])
                max_density_city = max(network_data.items(), key=lambda x: x[1]['road_density'])
                min_circuity_city = min(network_data.items(), key=lambda x: x[1]['avg_circuity'])
                max_size_city = max(network_data.items(), key=lambda x: x[1]['node_count'])
                
                f.write(f"**é•·é‡çœŒä¸»è¦éƒ½å¸‚ã® Space Syntax åˆ†æã‹ã‚‰å¾—ã‚‰ã‚ŒãŸçŸ¥è¦‹**:\n\n")
                
                f.write(f"1. **æœ€ã‚‚è¤‡é›‘ãªé“è·¯æ§‹é€ **: {max_alpha_city[0]} (Î±æŒ‡æ•°: {max_alpha_city[1]['alpha_index']:.2f})\n")
                f.write(f"   - ç’°çŠ¶è·¯ã‚„ä»£æ›¿ãƒ«ãƒ¼ãƒˆãŒè±Šå¯Œã§ã€äº¤é€šã®åˆ†æ•£åŠ¹æœãŒæœŸå¾…ã§ãã‚‹\n\n")
                
                f.write(f"2. **æœ€ã‚‚é«˜å¯†åº¦ãªé“è·¯ç¶²**: {max_density_city[0]} (é“è·¯å¯†åº¦: {max_density_city[1]['road_density']:.2f} km/kmÂ²)\n")
                f.write(f"   - é«˜åº¦ã«éƒ½å¸‚åŒ–ã•ã‚Œã¦ãŠã‚Šã€ã‚¢ã‚¯ã‚»ã‚¹æ€§ã«å„ªã‚Œã¦ã„ã‚‹\n\n")
                
                f.write(f"3. **æœ€ã‚‚åŠ¹ç‡çš„ãªç§»å‹•**: {min_circuity_city[0]} (å¹³å‡è¿‚å›ç‡: {min_circuity_city[1]['avg_circuity']:.2f})\n")
                f.write(f"   - ç›´ç·šçš„ãªç§»å‹•ãŒå¯èƒ½ã§ã€æ™‚é–“åŠ¹ç‡ã®è‰¯ã„äº¤é€šãŒæœŸå¾…ã§ãã‚‹\n\n")
                
                f.write(f"4. **æœ€å¤§è¦æ¨¡ã®ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯**: {max_size_city[0]} ({max_size_city[1]['node_count']:,}ãƒãƒ¼ãƒ‰)\n")
                f.write(f"   - åºƒåŸŸçš„ãªäº¤é€šçµç¯€ç‚¹ã¨ã—ã¦ã®æ©Ÿèƒ½ã‚’æŒã¤\n\n")
                
                # åœ°åŸŸç‰¹æ€§ã«åŸºã¥ãè€ƒå¯Ÿ
                f.write(f"**åœ°åŸŸç‰¹æ€§ã«åŸºã¥ãåˆ†æ**:\n\n")
                f.write(f"é•·é‡çœŒã®å„éƒ½å¸‚ã¯ã€ãã‚Œãã‚Œç•°ãªã‚‹åœ°ç†çš„ãƒ»æ­´å²çš„èƒŒæ™¯ã‚’æŒã£ã¦ãŠã‚Šã€")
                f.write(f"é“è·¯ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®æ§‹é€ ã«ã‚‚ãã®ç‰¹å¾´ãŒåæ˜ ã•ã‚Œã¦ã„ã¾ã™:\n\n")
                
                for city_jp in analyzed_cities:
                    if city_jp == "æ¾æœ¬å¸‚":
                        f.write(f"- **æ¾æœ¬å¸‚**: æ¾æœ¬ç›†åœ°ã®ä¸­å¿ƒéƒ½å¸‚ã¨ã—ã¦ã€æ¯”è¼ƒçš„è¨ˆç”»çš„ãªé“è·¯é…ç½®ãŒ")
                        f.write(f"è¦‹ã‚‰ã‚Œã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚åŸä¸‹ç”ºã¨ã—ã¦ã®æ­´å²çš„è¡—åŒºã¨ã€")
                        f.write(f"ç¾ä»£çš„ãªéƒ½å¸‚è¨ˆç”»ãŒæ··åœ¨ã—ãŸæ§‹é€ ãŒç‰¹å¾´çš„ã§ã™ã€‚\n\n")
                    elif city_jp == "é•·é‡å¸‚":
                        f.write(f"- **é•·é‡å¸‚**: å–„å…‰å¯ºã‚’ä¸­å¿ƒã¨ã—ãŸæ”¾å°„çŠ¶ã®é“è·¯æ§‹é€ ã¨ã€")
                        f.write(f"çœŒåºæ‰€åœ¨åœ°ã¨ã—ã¦ã®åºƒåŸŸçš„ãªäº¤é€šçµç¯€æ©Ÿèƒ½ã‚’ä½µã›æŒã¤ã¨")
                        f.write(f"è€ƒãˆã‚‰ã‚Œã¾ã™ã€‚æ­´å²çš„è¡—åŒºã¨æ–°å¸‚è¡—åœ°ã®æ··åœ¨ãŒç‰¹å¾´ã§ã™ã€‚\n\n")
                    elif city_jp == "ä¸Šç”°å¸‚":
                        f.write(f"- **ä¸Šç”°å¸‚**: ä¸Šç”°ç›†åœ°ã®åœ°å½¢åˆ¶ç´„ã¨ã€çœŸç”°æ°ã®åŸä¸‹ç”ºã¨ã—ã¦")
                        f.write(f"ã®æ­´å²çš„ãªè¡—åŒºæ§‹é€ ãŒã€ç¾åœ¨ã®é“è·¯ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã«å½±éŸ¿ã‚’")
                        f.write(f"ä¸ãˆã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚\n\n")
            
            # ä»Šå¾Œã®æ´»ç”¨æ–¹é‡
            f.write(f"### ä»Šå¾Œã®æ´»ç”¨æ–¹é‡\n\n")
            f.write(f"**éƒ½å¸‚è¨ˆç”»ã¸ã®å¿œç”¨**:\n")
            f.write(f"- å¾ªç’°æ€§ã®ä½ã„éƒ½å¸‚ã§ã¯ã€ç’°çŠ¶é“è·¯ã‚„ä»£æ›¿ãƒ«ãƒ¼ãƒˆã®æ•´å‚™ã‚’æ¤œè¨\n")
            f.write(f"- è¿‚å›ç‡ã®é«˜ã„éƒ½å¸‚ã§ã¯ã€ç›´ç·šçš„ãªã‚¢ã‚¯ã‚»ã‚¹è·¯ã®æ”¹å–„ã‚’æ¤œè¨\n")
            f.write(f"- é“è·¯å¯†åº¦ã®æ ¼å·®ã‚’è€ƒæ…®ã—ãŸã€ãƒãƒ©ãƒ³ã‚¹ã®å–ã‚ŒãŸäº¤é€šã‚¤ãƒ³ãƒ•ãƒ©æ•´å‚™\n\n")
            
            f.write(f"**äº¤é€šæ”¿ç­–ã¸ã®ç¤ºå”†**:\n")
            f.write(f"- å„éƒ½å¸‚ã®é“è·¯æ§‹é€ ç‰¹æ€§ã«å¿œã˜ãŸäº¤é€šæµåˆ¶å¾¡\n")
            f.write(f"- å…¬å…±äº¤é€šã‚·ã‚¹ãƒ†ãƒ ã®æœ€é©é…ç½®è¨ˆç”»\n")
            f.write(f"- ç½å®³æ™‚ã®ä»£æ›¿ãƒ«ãƒ¼ãƒˆç¢ºä¿æˆ¦ç•¥\n\n")
            
            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
            f.write(f"---\n\n")
            f.write(f"## ğŸ“‹ åˆ†æãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿\n\n")
            f.write(f"- **åˆ†ææ‰‹æ³•**: Space Syntax Analysis\n")
            f.write(f"- **ä½¿ç”¨ãƒ‡ãƒ¼ã‚¿**: OpenStreetMap\n")
            f.write(f"- **åˆ†æãƒ„ãƒ¼ãƒ«**: OSMnx, NetworkX\n")
            f.write(f"- **åˆ†ææ—¥æ™‚**: {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')}\n")
            f.write(f"- **ãƒ¬ãƒãƒ¼ãƒˆå½¢å¼**: Markdown\n")
            f.write(f"- **æ–‡å­—ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°**: UTF-8\n\n")
            
            # å…è²¬äº‹é …
            f.write(f"## âš ï¸ å…è²¬äº‹é …\n\n")
            f.write(f"æœ¬åˆ†æçµæœã¯ OpenStreetMap ãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ãç†è«–çš„åˆ†æã§ã‚ã‚Šã€")
            f.write(f"å®Ÿéš›ã®äº¤é€šæµã‚„éƒ½å¸‚æ©Ÿèƒ½ã‚’å®Œå…¨ã«åæ˜ ã™ã‚‹ã‚‚ã®ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
            f.write(f"éƒ½å¸‚è¨ˆç”»ã‚„æ”¿ç­–æ±ºå®šã®éš›ã«ã¯ã€æœ¬åˆ†æçµæœã‚’å‚è€ƒè³‡æ–™ã®ä¸€ã¤ã¨ã—ã¦")
            f.write(f"æ´»ç”¨ã—ã€ä»–ã®èª¿æŸ»ãƒ»ãƒ‡ãƒ¼ã‚¿ã¨ç·åˆçš„ã«æ¤œè¨ã™ã‚‹ã“ã¨ã‚’æ¨å¥¨ã—ã¾ã™ã€‚\n")
        
        print(f"ğŸ“‹ æ¯”è¼ƒåˆ†æãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆå®Œäº†: {report_file.name}")
        
        # è¿½åŠ : CSVã‚µãƒãƒªãƒ¼ã‚‚ç”Ÿæˆ
        generate_csv_summary(successful_analyses, output_dir, timestamp)
        
    except Exception as e:
        logger.error(f"ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
        print(f"âŒ ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")


def generate_csv_summary(successful_analyses, output_dir, timestamp):
    """CSVå½¢å¼ã®ã‚µãƒãƒªãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ"""
    try:
        csv_file = output_dir / f"analysis_summary_{timestamp}.csv"
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ç”¨ã®ãƒ‡ãƒ¼ã‚¿ã‚’æº–å‚™
        summary_data = []
        
        for location, results, analysis_type, execution_time in successful_analyses:
            city_jp = CITY_NAMES_JP.get(location, location)
            basic_analysis = results.get('basic_analysis', {})
            major_network = basic_analysis.get('major_network', {})
            integrated_evaluation = results.get('integrated_evaluation', {})
            
            row_data = {
                'éƒ½å¸‚å': city_jp,
                'è‹±èªå': location,
                'åˆ†æã‚¿ã‚¤ãƒ—': analysis_type,
                'å®Ÿè¡Œæ™‚é–“_ç§’': execution_time,
                'ãƒãƒ¼ãƒ‰æ•°': major_network.get('node_count', 0),
                'ã‚¨ãƒƒã‚¸æ•°': major_network.get('edge_count', 0),
                'å¹³å‡æ¬¡æ•°': major_network.get('avg_degree', 0),
                'æœ€å¤§æ¬¡æ•°': major_network.get('max_degree', 0),
                'å¯†åº¦': major_network.get('density', 0),
                'Î±æŒ‡æ•°': major_network.get('alpha_index', 0),
                'Î²æŒ‡æ•°': major_network.get('beta_index', 0),
                'Î³æŒ‡æ•°': major_network.get('gamma_index', 0),
                'é“è·¯å¯†åº¦_km_per_km2': major_network.get('road_density', 0),
                'å¹³å‡è¿‚å›ç‡': major_network.get('avg_circuity', 0),
                'é€£çµæˆåˆ†æ•°': major_network.get('num_components', 0)
            }
            
            # çµ±åˆè©•ä¾¡ãƒ‡ãƒ¼ã‚¿ï¼ˆæ‹¡å¼µåˆ†æã®å ´åˆï¼‰
            if integrated_evaluation and not integrated_evaluation.get('error'):
                row_data.update({
                    'å›éŠæ€§ã‚¹ã‚³ã‚¢': integrated_evaluation.get('connectivity_score', 0),
                    'ã‚¢ã‚¯ã‚»ã‚¹æ€§ã‚¹ã‚³ã‚¢': integrated_evaluation.get('accessibility_score', 0),
                    'åŠ¹ç‡æ€§ã‚¹ã‚³ã‚¢': integrated_evaluation.get('efficiency_score', 0),
                    'ç·åˆã‚¹ã‚³ã‚¢': integrated_evaluation.get('overall_score', 0),
                    'è©•ä¾¡ãƒ¬ãƒ™ãƒ«': integrated_evaluation.get('evaluation_level', '')
                })
            else:
                row_data.update({
                    'å›éŠæ€§ã‚¹ã‚³ã‚¢': None,
                    'ã‚¢ã‚¯ã‚»ã‚¹æ€§ã‚¹ã‚³ã‚¢': None,
                    'åŠ¹ç‡æ€§ã‚¹ã‚³ã‚¢': None,
                    'ç·åˆã‚¹ã‚³ã‚¢': None,
                    'è©•ä¾¡ãƒ¬ãƒ™ãƒ«': ''
                })
            
            summary_data.append(row_data)
        
        # CSVãƒ•ã‚¡ã‚¤ãƒ«ã«æ›¸ãè¾¼ã¿
        import pandas as pd
        df = pd.DataFrame(summary_data)
        df.to_csv(csv_file, index=False, encoding='utf-8-sig')  # Excelå¯¾å¿œã®ãŸã‚BOMä»˜ãUTF-8
        
        print(f"ğŸ“Š CSVã‚µãƒãƒªãƒ¼ç”Ÿæˆå®Œäº†: {csv_file.name}")
        
    except Exception as e:
        logger.warning(f"CSVã‚µãƒãƒªãƒ¼ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")


def demo_axial_analysis_only():
    """è»¸ç·šåˆ†æå˜ä½“ãƒ‡ãƒ¢"""
    print("\nğŸ”„ è»¸ç·šåˆ†æå˜ä½“ãƒ‡ãƒ¢å®Ÿè¡Œä¸­...")
    
    try:
        from space_syntax_analyzer.core.axial import AxialAnalyzer
        
        axial_analyzer = AxialAnalyzer()
        print("âœ… è»¸ç·šåˆ†æã‚¢ãƒŠãƒ©ã‚¤ã‚¶ãƒ¼åˆæœŸåŒ–æˆåŠŸ")
        
        # ãƒ€ãƒŸãƒ¼ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã§ã®åˆ†æ
        import networkx as nx
        dummy_network = nx.grid_2d_graph(5, 5)
        
        results = axial_analyzer.calculate_axial_summary(dummy_network)
        print(f"âœ… è»¸ç·šåˆ†æå®Œäº†: {results.get('network_metrics', {})}")
        
    except Exception as e:
        logger.error(f"è»¸ç·šåˆ†æå˜ä½“ãƒ‡ãƒ¢ã‚¨ãƒ©ãƒ¼: {e}")
        print("âŒ è»¸ç·šåˆ†æå˜ä½“ãƒ‡ãƒ¢ã‚‚å¤±æ•—ã—ã¾ã—ãŸ")


def demo_basic_analysis_fallback():
    """åŸºæœ¬åˆ†æãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯"""
    print("\nğŸ”„ åŸºæœ¬åˆ†æãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å®Ÿè¡Œä¸­...")
    
    try:
        from space_syntax_analyzer.core.analyzer import SpaceSyntaxAnalyzer
        
        analyzer = SpaceSyntaxAnalyzer()
        
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ™‚ã‚‚é•·é‡çœŒéƒ½å¸‚ã‚’ä½¿ç”¨
        fallback_location = "Matsumoto, Nagano, Japan"  # æ¾æœ¬å¸‚ã‚’ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯åœ°ç‚¹ã«
        print(f"ğŸ“ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯åˆ†æå¯¾è±¡: æ¾æœ¬å¸‚")
        
        results = analyzer.analyze_place(fallback_location)
        
        if not results.get('error', False):
            print("âœ… åŸºæœ¬åˆ†ææˆåŠŸ")
            display_basic_results(results)
        else:
            print(f"âŒ åŸºæœ¬åˆ†æã‚¨ãƒ©ãƒ¼: {results.get('error_message', 'ä¸æ˜')}")
        
    except Exception as e:
        logger.error(f"åŸºæœ¬åˆ†æãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚¨ãƒ©ãƒ¼: {e}")
        print("âŒ åŸºæœ¬åˆ†æãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚‚å¤±æ•—ã—ã¾ã—ãŸ")


def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    print("ğŸŒŸ æœ€é©åŒ–ç‰ˆæ‹¡å¼µ Space Syntax Analyzer ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³")
    print("="*80)
    
    # æ‹¡å¼µæ©Ÿèƒ½ä¾å­˜é–¢ä¿‚ãƒã‚§ãƒƒã‚¯
    print("ğŸ” æ‹¡å¼µæ©Ÿèƒ½ä¾å­˜é–¢ä¿‚ãƒã‚§ãƒƒã‚¯ä¸­...")
    
    # å¿…é ˆãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ãƒã‚§ãƒƒã‚¯
    required_libs = ["osmnx", "networkx", "pandas", "matplotlib", "numpy", "scipy", "shapely"]
    optional_libs = ["geopandas", "scikit-learn", "plotly", "folium"]
    
    missing_required = []
    missing_optional = []
    
    for lib in required_libs:
        try:
            __import__(lib)
            print(f"   âœ… {lib}")
        except ImportError:
            print(f"   âŒ {lib}")
            missing_required.append(lib)
    
    for lib in optional_libs:
        try:
            __import__(lib)
            print(f"   âœ… {lib} (ã‚ªãƒ—ã‚·ãƒ§ãƒ³)")
        except ImportError:
            print(f"   âš ï¸ {lib} (ã‚ªãƒ—ã‚·ãƒ§ãƒ³ãƒ»æœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«)")
            missing_optional.append(lib)
    
    if missing_required:
        print(f"\nâŒ å¿…é ˆãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒä¸è¶³: {', '.join(missing_required)}")
        print("ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«: uv add " + " ".join(missing_required))
        return
    
    if missing_optional:
        print(f"\nâš ï¸ ã‚ªãƒ—ã‚·ãƒ§ãƒ³æ©Ÿèƒ½åˆ¶é™: {', '.join(missing_optional)}")
        print("ãƒ•ãƒ«æ©Ÿèƒ½ä½¿ç”¨ã«ã¯: uv add " + " ".join(missing_optional))
    
    print("âœ… æœ€é©åŒ–æ‹¡å¼µæ©Ÿèƒ½ã®å®Ÿè¡ŒãŒå¯èƒ½ã§ã™")
    
    # æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆçŠ¶æ³ã®è¡¨ç¤º
    if JAPANESE_FONT_AVAILABLE:
        print("âœ… æ—¥æœ¬èªãƒãƒ£ãƒ¼ãƒˆç”ŸæˆãŒå¯èƒ½ã§ã™")
    else:
        print("âš ï¸ æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆæœªå¯¾å¿œ - è‹±èªãƒãƒ£ãƒ¼ãƒˆã§ä»£æ›¿ã—ã¾ã™")
    
    # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ä½œæˆ
    output_dir = Path("demo_output")
    output_dir.mkdir(exist_ok=True)
    print(f"ğŸ“ å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {output_dir.absolute()}")
    
    # ãƒ‡ãƒ¢é¸æŠãƒ¡ãƒ‹ãƒ¥ãƒ¼
    print("\nğŸ“‹ åˆ©ç”¨å¯èƒ½ãªãƒ‡ãƒ¢:")
    print("   1: æœ€é©åŒ–åŒ…æ‹¬åˆ†æãƒ‡ãƒ¢ï¼ˆæ¨å¥¨ï¼‰")
    print("   2: è»¸ç·šåˆ†æå˜ä½“ãƒ‡ãƒ¢")
    print("   3: åŸºæœ¬æ©Ÿèƒ½ãƒ‡ãƒ¢")
    print("   a: å…¨ãƒ‡ãƒ¢å®Ÿè¡Œ")
    
    try:
        choice = input("\né¸æŠã—ã¦ãã ã•ã„ (1-3, a, q=çµ‚äº†): ").strip().lower()
        
        if choice == 'q':
            print("ğŸ‘‹ ãƒ‡ãƒ¢ã‚’çµ‚äº†ã—ã¾ã™")
            return
        elif choice == '1':
            demo_enhanced_comprehensive_analysis()
        elif choice == '2':
            demo_axial_analysis_only()
        elif choice == '3':
            demo_basic_analysis_fallback()
        elif choice == 'a':
            print("ğŸ“‹ å…¨ãƒ‡ãƒ¢å®Ÿè¡Œ:")
            demo_enhanced_comprehensive_analysis()
            demo_axial_analysis_only()
            demo_basic_analysis_fallback()
        else:
            print("âŒ ç„¡åŠ¹ãªé¸æŠã§ã™")
            return
        
    except KeyboardInterrupt:
        print("\nğŸ‘‹ ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã‚ˆã£ã¦ä¸­æ–­ã•ã‚Œã¾ã—ãŸ")
    except Exception as e:
        logger.error(f"ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
        print(f"âŒ äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}")
    
    print(f"\nğŸ“ çµæœãƒ•ã‚¡ã‚¤ãƒ«ã¯ {output_dir.absolute()} ã«ä¿å­˜ã•ã‚Œã¦ã„ã¾ã™")
    print(f"ğŸ’¡ å•é¡ŒãŒç™ºç”Ÿã—ãŸå ´åˆã¯ã€ãƒ­ã‚°ã‚’ç¢ºèªã™ã‚‹ã‹åº§æ¨™æŒ‡å®šã§ã®åˆ†æã‚’ãŠè©¦ã—ãã ã•ã„")


if __name__ == "__main__":
    main()